---
title: Monitoring PCF Healthwatch
owner: PCF Healthwatch
---

This topic explains how to monitor the health of Pivotal Cloud Foundry (PCF) Healthwatch using the metrics and key performance indicators (KPIs) generated by the service.

For general information about monitoring PCF, see [Monitoring Pivotal Cloud Foundry](https://docs.pivotal.io/pivotalcf/monitoring/index.html).

## <a id="aboutMetrics"></a>About Metrics

PCF Healthwatch emits metrics in the following format:

<pre>
origin:"healthwatch" eventType:ValueMetric timestamp:1509638101820496694 deployment:"healthwatch-app-dev-v1-1" job:"healthwatch-forwarder" index:"097f4b1e-5ca8-4866-82d5-00883798dad4" ip:"10.0.16.29" valueMetric:&lt;name:"healthwatch.metrics.published" value:38 unit:"count"&gt;
</pre>

All PCF Healthwatch-emitted metrics have the `healthwatch` origin.

## <a id="keyPerformanceIndicators"></a>Key Performance Indicators for PCF Healthwatch

This section describes the KPIs that you can use to monitor the health and performance of PCF Healthwatch.

###<a id="firehose-disconnect"></a>Number of Healthwatch Nozzle Disconnects from Firehose
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> healthwatch.ingestor.disconnects<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        Number of forced disconnects of the <a href="./architecture.html">PCF Healthwatch data ingestor nozzle</a> from the Firehose.<br/><br/>
        <strong>Use</strong>: An unusual increase in the number of disconnects from the Firehose typically indicates that the nozzle needs to be scaled up. The Firehose disconnects nozzles that are slow consumers to protect apps from backpressure. This metric can also spike during a PCF deployment because the Traffic Controller VMs restart, logging a disconnect.
        <br/><br/>
        A prolonged period of losing metrics as a result of disconnects can endanger the assessments that PCF Healthwatch makes using Firehose-based platform metrics.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: Dynamic<br/>
      <strong>Red critical</strong>: Dynamic</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         If no known deployment occurred and the spike is sustained, increase the number of Healthwatch Ingestor instances and monitor this metric to ensure it returns to a normal state.
         <br/><br/>
         Ingestor instances can be scaled in the Healthwatch Component Config tab of the PCF Healthwatch tile or using the <code>cf scale healthwatch-ingestor</code> command. While <code>cf scale</code> helps you to quickly scale the instances, you should also update the tile configuration so that the next deployment does not override the manual scaling.
      </td>
   </tr>
</table>

###<a id="loader-dropped"></a>Number of Metrics Dropped by Healthwatch Data Loader
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> healthwatch.loader.dropped<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        Number of metrics dropped by the <a href="./architecture.html">PCF Healthwatch data loader</a>, which loads incoming data into the Healthwatch datastore.
        <br/><br/>
        <strong>Use</strong>: An unusual increase in the number of dropped metrics by the Healthwatch Loader likely indicates that this component needs to be scaled up. A prolonged period of dropping metrics could endanger the assessments PCF Healthwatch makes from Firehose-based platform metrics.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: Dynamic<br/>
      <strong>Red critical</strong>: Dynamic</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Increase the number of Healthwatch Loader instances and monitor this metric to ensure it returns to a normal state.
         <br/><br/>
         Loader instances can be scaled within the Healthwatch Component Config tab of the PCF Healthwatch tile or using the <code>cf scale healthwatch-loader</code> command. While <code>cf scale</code> helps you to quickly scale the instances, you should also update the tile configuration so that the next deployment does not override the manual scaling.
      </td>
   </tr>
</table>

###<a id="ui-availability"></a>Healthwatch UI Availability
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> healthwatch.ui.available<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        The PCF Healthwatch UI is currently available. This assessment is made using a probe that looks for a successful response: 1 = available, 0 = not available, or timeout (10 s).
        <br/><br/>
        <strong>Use</strong>: Indicates that the Healthwatch UI is running and available to product end users. While an issue with the UI does not impact the assessments Healthwatch is making, loss of the UI can impact user ability to visually reference these assessments.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &le; 0.6<br/>
      <strong>Red critical</strong>: &le; 0.4</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Check to make sure the <code>healthwatch</code> application is running in the <code>system</code> org and <code>healthwatch</code> space.  Check the logs to look for any obvious errors.  Validate that the <code>/info</code> endpoint is available on the <code>healthwatch</code> application route.
      </td>
   </tr>
</table>

###<a id="cli-test-availability"></a>CLI Health Test Availability
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.check.cliCommand.probe.available<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        PCF Healthwatch has up-to-date results for the <a href="metrics.html#cli">CLI Command Health Test</a>, which means that the test was recently available.
        <br/><br/>
        Response: 1 = available, 0 = not available, or timeout (10 s)
        <br/><br/>
        An assessment of up-to-date results is made by looking for results within the configured run schedule plus timeout. For example, a test runner scheduled on 5-minute intervals with a 2-minute timeout must show a test result within the last 7 minutes to succeed.
        <br/><br/>
        <strong>Use</strong>: Indicates that PCF Healthwatch is assessing the current state of health for the CLI commands. If these continuous validation tests fail to make up-to-date assessments, they are no longer a reliable warning mechanism.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &le; 0.6<br/>
      <strong>Red critical</strong>: &le; 0.4</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Check to make sure the <code>cf-health-check</code> application is running in the <code>system</code> org and <code>healthwatch</code> space.  Check the logs to look for any obvious errors.
      </td>
   </tr>
</table>

###<a id="canary-test-availability"></a>Canary App Health Test Availability
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.check.CanaryApp.probe.available<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        PCF Healthwatch has up-to-date results for the <a href="metrics.html#canaryapp">Canary App Health Test</a>, which means that the test was recently available.
        <br/><br/>
        Response: 1 = available, 0 = not available, or timeout (10 s)
        <br/><br/>
        An assessment of up-to-date results is made by looking for results within the configured run schedule plus timeout. For example, a test runner scheduled on 5-minute intervals with a 2-minute timeout must show a test result within the last 7 minutes to succeed.
        <br/><br/>
        <strong>Use</strong>: Indicates that Healthwatch is assessing the current state of health for the canary app. If this continuous validation test fails to make up-to-date assessments, it is no longer a reliable warning mechanism.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &le; 0.6<br/>
      <strong>Red critical</strong>: &le; 0.4</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Check to make sure the <code>canary-health-check</code> application is running in the <code>system</code> org and <code>healthwatch</code> space.  Check the logs to look for any obvious errors.
         <br/><br/>
         Verify that Apps Manager is running and accessible via the URL configured in the <code>canary-health-check</code> application's <code>CANARY_URL</code> environment variable.
      </td>
   </tr>
</table>

###<a id="bosh-test-availability"></a>BOSH Director Health Test Availability
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.check.bosh.director.probe.available<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        PCF Healthwatch has up-to-date results for the <a href="metrics.html#bosh-director">BOSH Director Health Test</a>, which means that the test was recently available.
        <br/><br/>
        Response: 1 = available, 0 = not available, or timeout (10 s)
        <br/><br/>
        An assessment of up-to-date results is made by looking for results within the configured run schedule plus timeout. For example, a test runner scheduled on 5-minute intervals with a 2-minute timeout must show a test result within the last 7 minutes to succeed.
        <br/><br/>
        <strong>Use</strong>:  Indicates that PCF Healthwatch is assessing the current state of health for the BOSH Director. If this continuous validation test fails to make up-to-date assessments, it is no longer a reliable warning mechanism.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &le; 0.6<br/>
      <strong>Red critical</strong>: &le; 0.4</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Check to make sure the <code>bosh-health-check</code> application is running in the <code>system</code> org and <code>healthwatch</code> space.  Check the logs to look for any obvious errors.
         <br/><br/>
         SSH into the running <code>bosh-health-check</code> and copy the Bosh manifest from <code>/home/vcap/app/health_check_manifest.yml</code>.  Attempt to deploy it manually on the Bosh Director and check for errors.
      </td>
   </tr>
</table>

###<a id="opsman-test-availability"></a>Ops Manager Health Test Availability
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.check.OpsMan.probe.available<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        PCF Healthwatch has up-to-date results for the <a href="metrics.html#opsman">Ops Manager Health Test</a>, which means that the test was recently available.
        <br/><br/>
        Response: 1 = available, 0 = not available, or timeout (10 s)
        <br/><br/>
        An assessment of up-to-date results is made by looking for results within the configured run schedule plus timeout. For example, a test runner scheduled on 5-minute intervals with a 2-minute timeout must show a test result within the last 7 minutes to succeed.
        <br/><br/>
        <strong>Use</strong>: Indicates that PCF Healthwatch is assessing the current state of health for Ops Manager. If this continuous validation test fails to make up-to-date assessments, it is no longer a reliable warning mechanism.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &le; 0.6<br/>
      <strong>Red critical</strong>: &le; 0.4</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Check to make sure the <code>opsmanager-health-check</code> application is running in the <code>system</code> org and <code>healthwatch</code> space.  Check the logs to look for any obvious errors.
         <br/><br/>
         Verify that the Ops Manager is running and accessible via the URL configured in the <code>opsmanager-health-check</code> application's <code>OPSMANAGER_URL</code> environment variable.
      </td>
   </tr>
</table>

###<a id="super-metrics-published"></a>Number of Healthwatch Super Metrics Published to Firehose
<table>
   <tr><th colspan="2" style="text-align: center;"><br/>healthwatch.metrics.published<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        Number of Healthwatch <a href="metrics.html">assessment metrics</a> published back to the Firehose.
        <br/><br/>
        <strong>Use</strong>: An unusual drop in the number of assessment metrics published can indicate that PCF Healthwatch may be experiencing a computation or publication issue.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: Dynamic<br/>
      <strong>Red critical</strong>: Dynamic</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Validate that the <code>healthwatch-forwarder</code> VM is running.  Check all of the logs in <code>/var/vcap/sys/log</code> on the VM.  Validate that the <code>*-health-check</code> applications are running and not throwing any obvious errors in the logs in the <code>system</code> org and <code>healthwatch</code> space.
      </td>
   </tr>
</table>

##<a id="continuous-validation-tests"></a>Number of Healthwatch Continuous Validation Tests Executed

###<a id="cli-command-health-probe"></a>CLI Command Health
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.check.cliCommand.probe.count<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        Number of PCF Healthwatch <a href="metrics.html#cli">CLI Command Health</a> probe assessments completed in the measured time interval.
        <br/><br/>
        <strong>Use</strong>: For alerting purposes, Pivotal suggests alerting on <code>health.check.cliCommand.probe.available</code> instead. This metric is most helpful for additional diagnostics or secondary alerting.
        <br/><br/>
        Primary indicator of concern with this metric is an unexpected negative variance from the normal pattern of checks per test type. If an operator has not taken action that would impact the number of checks being made, like scaling the test runner or changing the frequency of the run, then an unexpected variance from normal would likely indicate problems in the test runner functionality.
        <br/><br/>
        In the default installation, these tests run every 5 minutes across 2 runner apps.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
</table>

###<a id="opsmanager-health-probe"></a>Ops Manager Health
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.check.OpsMan.probe.count<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        Number of PCF Healthwatch <a href="metrics.html#opsman">Ops Manager Health</a> probe assessments completed in the measured time interval.
        <br/><br/>
        <strong>Use</strong>: For alerting purposes, Pivotal suggests alerting on <code>health.check.OpsMan.probe.available</code> instead. This metric is most helpful for additional diagnostics or secondary alerting.
        <br/><br/>
        Primary indicator of concern with this metric is an unexpected negative variance from the normal pattern of checks per test type. If an operator has not taken action that would impact the number of checks being made, like scaling the test runner or changing the frequency of the run, then an unexpected variance from normal would likely indicate problems in the test runner functionality.
        <br/><br/>
        In the default installation, these tests run every 1 minute across 2 runner apps.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
</table>

###<a id="canary-health-probe"></a>Canary App Health
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.check.CanaryApp.probe.count<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        Number of PCF Healthwatch <a href="metrics.html#canaryapp">Canary App Health</a> probe assessments completed in the measured time interval.
        <br/><br/>
        <strong>Use</strong>: For alerting purposes, Pivotal suggests alerting on <code>health.check.CanaryApp.probe.available</code> instead. This metric is most helpful for additional diagnostics or secondary alerting.
        <br/><br/>
        Primary indicator of concern with this metric is an unexpected negative variance from the normal pattern of checks per test type. If an Operator has not taken action that would impact the number of checks being made, like scaling the test runner or changing the frequency of the run, then an unexpected variance from normal would likely indicate problems in the test runner functionality.
        <br/><br/>
        In the default installation, these tests run every 1 minutes across 2 runner apps.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
</table>

###<a id="bosh-health-probe"></a>BOSH Director Health
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.check.bosh.director.probe.count<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        Number of PCF Healthwatch <a href="metrics.html#bosh-director">BOSH Director Health</a> probe assessments completed in the measured time interval.
        <br/><br/>
        <strong>Use</strong>: For alerting purposes, Pivotal suggests alerting on <code>health.check.bosh.director.probe.available</code> instead. This metric is most helpful for additional diagnostics or secondary alerting.
        <br/><br/>
        Primary indicator of concern with this metric is an unexpected negative variance from the normal pattern of checks per test type. If an operator has not taken action that would impact the number of checks being made, like scaling the test runner or changing the frequency of the run, then an unexpected variance from normal would likely indicate problems in the test runner functionality.
        <br/><br/>
        In the default installation, these tests run every 10 minutes for 1 runner app.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
</table>

##<a id="other-metrics"></a>Other Metrics Available
###<a id="bosh-deployment-probe"></a>BOSH Deployment Check Probe
<table>
   <tr><th colspan="2" style="text-align: center;"><br/> health.bosh.deployment.probe.count<br/><br/></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>
        Number of PCF Healthwatch <a href="metrics.html#bosh-deployment">BOSH Deployment Occurrence</a> probes completed in the measured time interval.
        <br/><br/>
        <strong>Use</strong>: Primary indicator of concern with this metric is an unexpected negative variance from the normal pattern of checks per test type. If an operator has not taken action that would impact the number of checks being made, like scaling the test runner or changing the frequency of the run, then an unexpected variance from normal would likely indicate problems in the test runner functionality.
        <br/><br/>
        In the default installation, these tests run every 30 seconds across 2 runner apps.
        <br/><br/>
        <strong>Origin</strong>: Firehose<br/>
        <strong>Type</strong>: Gauge<br/>
        <strong>Frequency</strong>: 60 s<br/>
      </td>
   </tr>
</table>

