---
title: PCF Healthwatch Metrics
owner: PCF Healthwatch
---

This topic lists derived and generated metrics provided by Pivotal Cloud Foundry (PCF) Healthwatch. The metrics are used to monitor the health and performance of the PCF platform.

##<a id='cli'></a>Cloud Foundry CLI Health

The Cloud Foundry command line interface (CLI) enables developers to create and manage apps on PCF. PCF Healthwatch executes a continuous test suite validating the core app developer functions of the CLI.

See the table below for information on metrics related to Cloud Foundry CLI smoke tests.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>Can push</td>
  <td><code>healthwatch.health.check.cliCommand.push</code> and <code>healthwatch.health.check.cliCommand.push.timeout</code></td>
  <td>5 min</td>
  <td><code>1</code> = pass, <code>0</code> = fail, or <code>-1</code> = test did not run</td>
</tr>
<tr>
  <td>Can start</td>
  <td><code>healthwatch.health.check.cliCommand.start</code> and <code>healthwatch.health.check.cliCommand.start.timeout</code></td>
  <td>5 min</td>
  <td><code>1</code> = pass, <code>0</code> = fail, or <code>-1</code> = test did not run</td>
</tr>
<tr>
  <td>Receiving logs</td>
  <td><code>healthwatch.health.check.cliCommand.logs</code> and <code>healthwatch.health.check.cliCommand.logs.timeout</code></td>
  <td>5 min</td>
  <td><code>1</code> = pass, <code>0</code> = fail, or <code>-1</code> test did not run</td>
</tr>
<tr>
  <td>Can stop</td>
  <td><code>healthwatch.health.check.cliCommand.stop</code> and <code>healthwatch.health.check.cliCommand.stop.timeout</code></td>
  <td>5 min</td>
  <td><code>1</code> = pass, <code>0</code> = fail, or <code>-1</code> test did not run</td>
</tr>
<tr>
  <td>Can delete</td>
  <td><code>healthwatch.health.check.cliCommand.delete</code> and <code>healthwatch.health.check.cliCommand.delete.timeout</code></td>
  <td>5 min</td>
  <td><code>1</code> = pass, <code>0</code> = fail, or <code>-1</code> test did not run</td>
</tr>
<tr>
  <td>Test app push time</td>
  <td><code>healthwatch.health.check.cliCommand.pushTime</code></td>
  <td>5 min</td>
  <td>Time in ms</td>
</tr>
<tr>
  <td>Overall smoke test battery result</td>
  <td><code>healthwatch.health.check.cliCommand.success</code></td>
  <td>5 min</td>
  <td><code>1</code> = pass or <code>0</code> = fail</td>
</tr>
<tr>
  <td>Overall smoke test battery run time</td>
  <td><code>healthwatch.health.check.cliCommand.duration</code></td>
  <td>5 min</td>
  <td>Time in ms</td>
</tr>
</table>

<p class="note"><strong>Note</strong>: Timeout metrics are written only when a timeout occurs. Their value is always zero.</p>

##<a id='opsman'></a>Ops Manager Health

Issues with Ops Manager health can impact an operator's ability to perform an upgrade or to rescale the PCF platform when necessary. Therefore, it is recommended to continuously monitor Ops Manager availability. PCF Healthwatch executes this check as a part of its test suite.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>Ops Manager availability</td>
  <td><code>healthwatch.health.check.OpsMan.available</code></td>
  <td>1 min</td>
  <td><code>1</code> = pass or <code>0</code> = fail</td>
</tr>
</table>

##<a id='appsman'></a>Apps Manager Health

These metrics help users to monitor app availability and responsiveness. PCF Healthwatch uses Apps Manager as a canary app and continuously checks its health.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>Apps Manager availability</td>
  <td><code>healthwatch.health.check.AppsMan.available</code></td>
  <td>1 min</td>
  <td><code>1</code> = pass or <code>0</code> = fail</td>
</tr>
<tr>
  <td>Aps Manager response time</td>
  <td><code>healthwatch.health.check.AppsMan.responseTime</code></td>
  <td>1 min</td>
  <td>Time in ms</td>
</tr>
</table>

##<a id='bosh-director'></a>BOSH Director Health

Losing the BOSH Director does not significantly impact the experience of PCF end users. However, this issue means a loss of resiliency for BOSH-managed VMs. It is recommended to continuously monitor the BOSH Director health. PCF Healthwatch executes this check as a part of its test suite.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>BOSH Director health</td>
  <td><code>healthwatch.health.check.bosh.director.success</code> and <code>healthwatch.health.check.bosh.director.timeout</code></td>
  <td>10 min</td>
  <td><code>1</code> = pass or <code>0</code> = fail</td>
</tr>
</table>

<p class="note"><strong>Note</strong>: The timeout metric is written if a deploy or delete task takes more than 10 minutes.</p>

##<a id='loss-rates'></a>Loss Rates

This section lists metrics used to monitor Loggregator, the PCF component responsible for logging.

###<a id='firehose-loss'></a>Firehose Loss Rate

This metric calculation is recommended for automating and monitoring platform scaling. Two versions of the metric (per minute and per hour) are used to monitor the Loggregator Firehose. 

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Description</th>
</tr>
<tr>
  <td>Firehose loss rate</td>
  <td><code>healthwatch.Firehose.LossRate.1H</code> and <code>healthwatch.Firehose.LossRate.1M</code></td>
  <td>Loss rate per minute and per hour</td>
</tr>
</table>

###<a id='adapter-loss'></a>Adapter Loss Rate

This metric calculation is recommended for automating and monitoring platform scaling. The metric is used to monitor the Scalable Syslog feature of Loggregator.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Description</th>
</tr>
<tr>
  <td>Adapter loss rate (syslog drain performance)</td>
  <td><code>healthwatch.ScalableSyslog.Adapter.LossRate.1M</code></td>
  <td>Loss rate per minute</td>
</tr>
</table>

###<a id='rlp-loss'></a>Reverse Log Proxy Loss Rate

This metric calculation is recommended for automating and monitoring platform scaling. The metric is used to monitor the Scalable Syslog feature of Loggregator.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Description</th>
</tr>
<tr>
  <td>Reverse Log Proxy loss rate (syslog drain performance)</td>
  <td><code>healthwatch.ScalableSyslog.RLP.LossRate.1M</code></td>
  <td>Loss rate per minute</td>
</tr>
</table>

##<a id='capacity'></a>Capacity Metrics

This sections lists metrics used to monitor available memory, disk, and cell container capacity.

###<a id='memory'></a>Available Memory

This metric calculation is recommended for automating and monitoring platform scaling.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Description</th>
</tr>
<tr>
  <td>Available memory</td>
  <td><code>healthwatch.Diego.TotalPercentageAvailableMemoryCapacity.5M</code></td>
  <td>Percentage of available memory.</td>
</tr>
</table>

###<a id='disk'></a>Available Disk

This metric calculation is recommended for automating and monitoring platform scaling.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Description</th>
</tr>
<tr>
  <td>Available disk</td>
  <td><code>healthwatch.Diego.TotalPercentageAvailableDiskCapacity.5M</code></td>
  <td>Percentage of available disk.</td>
</tr>
</table>

###<a id='cell-container'></a>Available Cell Container Capacity

This metric calculation is recommended for automating and monitoring platform scaling.

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Description</th>
</tr>
<tr>
  <td>Available cell container capacity</td>
  <td><code>healthwatch.Diego.TotalPercentageAvailableContainerCapacity.5M</code></td>
  <td>Percentage of available cell container capacity.</td>
</tr>
</table>

##<a id='bosh-deployment'></a>BOSH Deployment Occurrence

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>BOSH deployment occurrence</td>
  <td><code>healthwatch.bosh.deployment</code></td>
  <td>30 sec</td>
  <td><code>1</code> = a running deployment or <code>0</code> = not a running deployment</td>
</tr>
</table>

##<a id='other-metrics'></a>Other Platform Metrics

###<a id='job-health'></a>Job Health

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>Job health</td>
  <td><code>system.healthy</code></td>
  <td>1 min</td>
  <td>A BOSH health metric used for every VM in the CF deployment. This does not include additional deployments, such as MySQL or Redis.</td>
</tr>
</table>

###<a id='job-vitals'></a>Job Vitals

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>CPU utilization</td>
  <td><code>system.cpu.user</code></td>
  <td>1 min</td>
  <td>Percentage of CPU used.</td>
</tr>
<tr>
  <td>Memory utilization</td>
  <td><code>system.mem.percent</code></td>
  <td>1 min</td>
  <td>Percentage of system memory used.</td>
</tr>
<tr>
  <td>Disk utilization</td>
  <td><code>system.disk.system.percent</code></td>
  <td>1 min</td>
  <td>Percentage of system disk used.</td>
</tr>
<tr>
  <td>Persistent disk utilization</td>
  <td><code>system.disk.persistent.percent</code></td>
  <td>1 min</td>
  <td>Percentage of persistent disk used.</td>
</tr>
<tr>
  <td>Ephemeral disk utilization</td>
  <td><code>system.disk.ephemeral.percent</code></td>
  <td>1 min</td>
  <td>Percentage of ephemeral disk used.</td>
</tr>
</table>

###<a id='kpis-capacity'></a>Capacity

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>Available memory</td>
  <td><code>rep.CapacityRemainingMemory</code></td>
  <td>1 min</td>
  <td>Amount of memory (MiB) available for a Diego cell to allocate to containers.</td>
</tr>
<tr>
  <td>Available disk</td>
  <td><code>rep.CapacityRemainingDisk</code></td>
  <td>1 min</td>
  <td>Amount of disk (MiB) available for a Diego cell to allocate to containers.</td>
</tr>
</table>

###<a id='app-instances'></a>Application Instances
<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>Current running AIs and change in running AIs</td>
  <td><code>bbs.LRPsRunning</code></td>
  <td>During events</td>
  <td>Total number of LRP instances running on Diego cells.</td>
</tr>
<tr>
  <td>Crashed AIs</td>
  <td><code>bbs.CrashedActualLRPs</code></td>
  <td>30 sec</td>
  <td>Total number of LRP instances that have crashed in a deployment.</td>
</tr>
</table>

For more information about the lifecycle of an app container and crash events, see [Crash Events](https://docs.pivotal.io/pivotalcf/1-11/devguide/deploy-apps/app-lifecycle.html#crash-events)&nbsp;. 

###<a id='logging'></a>Logging Performance

<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>Throughput</td>
  <td><code>DopplerServer.listeners.totalReceivedMessageCount</code></td>
  <td>5 sec</td>
  <td>Total number of messages received across all Doppler listeners.</td>
</tr>
</table>

###<a id='router'></a>Router
<table class="nice">
<tr>
  <th>Test</th>
  <th>Metric</th>
  <th>Frequency</th>
  <th>Description</th>
</tr>
<tr>
  <td>Router throughput</td>
  <td><code>gorouter.total_requests</code></td>
  <td>5 sec</td>
  <td>Lifetime number of requests completed by the Gorouter VM.</td>
</tr>
<tr>
  <td>Router latency</td>
  <td><code>gorouter.latency</code></td>
  <td>Emitted per Gorouter request</td>
  <td>Time (ms) the Gorouter takes to handle requests to its app endpoints.</td>
</tr>
<tr>
  <td>Router jobs CPU</td>
  <td><code>system.cpu.user</code></td>
  <td>1 min</td>
  <td>Percentage of CPU used by a Gorouter job.</td>
</tr>
<tr>
  <td>502 bad gateways</td>
  <td><code>gorouter.bad_gateways</code></td>
  <td>5 sec</td>
  <td>Lifetime number of bad gateways, or 502 responses, from Gorouter itself.</td>
</tr>
</table>
