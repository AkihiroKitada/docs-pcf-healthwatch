---
title: Healthwatch Metrics
owner: Healthwatch
---

<strong><%= modified_date %></strong>

This topic describes the metrics that the Healthwatch Exporter for VMware Tanzu Application
Service for VMs (TAS for VMs) tile and the Healthwatch Exporter for Tanzu Kubernetes Grid Integrated
(TKGI) tile generate.


## <a id='overview'></a> Overview of Healthwatch Metrics

Healthwatch Exporter for TAS for VMs and Healthwatch Exporter for TKGI deploy metric exporter
VMs to generate component metrics and service level indicators (SLIs) related to the health
of your TAS for VMs and TKGI deployments. Each metric exporter VM exposes these metrics and
SLIs on a Prometheus exposition endpoint, `/metrics`.

The Prometheus VM that exists within your metrics monitoring system then scrapes each `/metrics`
endpoints on the metric exporter VMs and imports those metrics into your monitoring system.
You can configure the frequency at which the Prometheus VM scrapes the `/metrics` endpoints
in the **Prometheus Configuration** pane of the Healthwatch tile. To configure the scrape interval
for the Prometheus VM, see [Configure Prometheus](installing.html#prometheus) in _Installing,
Configuring, and Deploying Healthwatch_.

For more information about , see [Reference Architecture](architecture.html).


## <a id='bosh-sli'></a> BOSH SLIs

In an Ops Manager foundation, the BOSH Director manages the VMs that each tile deploys. If
the BOSH Director fails or is not responsive, the VMs that the BOSH Director manages also fail.
Healthwatch Exporter for TAS for VMs and Healthwatch Exporter for TKGI deploy two VMs that
continuously test the functionality of the BOSH Director: the BOSH health metric exporter VM
and the BOSH deployment metric exporter.

### <a id='bosh-health-exporter'></a> BOSH Health Metric Exporter VM

Healthwatch Exporter for TAS for VMs and Healthwatch Exporter for TKGI periodically [how often is this? Daily? Hourly? Every ten minutes like in Healthwatch 1.7?] deploy the BOSH health metric exporter VM, `bosh-health-exporter`. The BOSH health metric exporter VM creates a BOSH deployment and runs a suite of SLI tests on it to validate the functionality of the BOSH Director. After the SLI tests are complete, the BOSH health metric exporter VM deletes the BOSH deployment. The Healthwatch Exporter tile then deletes the BOSH health metric exporter VM.

The following table describes each metric the BOSH health metric exporter VM generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>bosh_sli_duration_seconds_bucket{exported_job="bosh-health-exporter"}</code></td>
    <td>The number of seconds the BOSH health SLI test suite takes to run [each time the whole suite runs? each time each specific SLI test within the suite runs?], grouped by duration.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_duration_seconds_count{exported_job="bosh-health-exporter"}</code></td>
    <td>The total number of BOSH health SLI test suite duration metrics in all buckets. [What are these buckets? Do we need to define them?]</td>
  </tr>
  <tr>
    <td><code>bosh_sli_duration_seconds_sum{exported_job="bosh-health-exporter"}</code></td>
    <td>The total value of the BOSH health SLI test suite duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_exporter_status{exported_job="bosh-health-exporter"}</code></td>
    <td>The health status of the BOSH health metric exporter VM. A value of <code>1</code>
      indicates that the BOSH health metric exporter VM is running and healthy.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_failures_total{exported_job="bosh-health-exporter"}</code></td>
    <td>The total number of times that [the BOSH health SLI test suite fails? specific tests within the BOSH health SLI test suite fail?].</td>
  </tr>
  <tr>
    <td><code>bosh_sli_run_duration_seconds{exported_job="bosh-health-exporter"}</code></td>
    <td>The number of seconds the BOSH health SLI test suite takes to run. [On average? Each time?]</td>
  </tr>
  <tr>
    <td><code>bosh_sli_runs_total{exported_job="bosh-health-exporter"}</code></td>
    <td>The total number of times the BOSH health SLI test suite runs. To see the failure rate
      of <code>bosh_sli_runs_total{exported_job="bosh-health-exporter"}</code>, divide the
      value of <code>bosh_sli_failures_total{exported_job="bosh-health-exporter"}</code> by
      the value of <code>bosh_sli_runs_total{exported_job="bosh-health-exporter"}</code>.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_duration_seconds_bucket{exported_job="bosh-health-exporter"}</code></td>
    <td>The number of seconds it takes [a particular task? each task?] to run, grouped by duration.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_duration_seconds_count{exported_job="bosh-health-exporter"}</code></td>
    <td>The total number of BOSH health SLI test suite task duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_duration_seconds_sum{exported_job="bosh-health-exporter"}</code></td>
    <td>The total value of the BOSH health SLI test suite task duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_run_duration_seconds{exported_job="bosh-health-exporter"}</code></td>
    <td>The number of seconds it takes for a particular task to run. [How do we know which task this metric refers to?]</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_runs_total{exported_job="bosh-health-exporter"}</code></td>
    <td>The total number of times a particular task runs [each time the whole suite runs? each time each specific SLI test within the suite runs?]. To see the failure rate of <code>bosh_sli_task_runs_total{exported_job="bosh-health-exporter"}</code>, divide the value of <code>bosh_sli_task_failures{exported_job="bosh-health-exporter"}</code> by the value of <code>bosh_sli_task_runs{exported_job="bosh-health-exporter"}</code>.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_failures_total{exported_job="bosh-health-exporter",task="delete"}</code></td>
    <td>The total number of times the <code>bosh delete-deployment</code> command fails.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_failures_total{exported_job="bosh-health-exporter",task="deploy"}</code></td>
    <td>The total number of times the <code>bosh deploy</code> command fails.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_failures_total{exported_job="bosh-health-exporter",task="deployments"}</code></td>
    <td>The total number of times the <code>bosh deployments</code> command fails.</td>
  </tr>
</table>

### <a id='bosh-deployments-exporter'></a> BOSH Deployment Metric Exporter VM

The BOSH deployment metric exporter VM, `bosh-deployments-exporter`, periodically [how periodically? Only while `bosh-health-exporter` is still deployed? Does it communicate with `bosh-health-exporter` in any way?] checks to see if any BOSH deployments other than the one created by the BOSH health metric exporter VM are running. [What would happen if other BOSH deployments were running at the same time? Where are these BOSH deployments coming from? Isn't the whole thing running on a BOSH deployment in the first place?]

The following table describes each metric the BOSH deployment metric exporter VM generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>bosh_deployments_status</code></td>
    <td>Whether any BOSH deployments other than the one created by the BOSH health metric exporter
      VM are running. A value of <code>1</code> indicates that other BOSH deployments are running
      on the BOSH Director. [Can it be multiple BOSH deployments at once, or does only one other typically run at the same time?]</td>
  </tr>
  <tr>
    <td><code>bosh_sli_duration_seconds_bucket{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The number of seconds the BOSH deployment SLI test suite takes to run [each time the whole suite runs? each time each specific SLI test within the suite runs?], grouped by duration.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_duration_seconds_count{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The total number of BOSH deployment SLI test suite duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_duration_seconds_sum{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The total value of the BOSH deployment SLI test suite duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_exporter_status{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The health status of the BOSH deployment metric exporter VM. A value of <code>1</code>
      indicates that the BOSH deployment metric exporter VM is running and healthy.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_failures_total{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The total number of times that [the BOSH deployment SLI test suite fails? specific tests within the BOSH deployment SLI test suite fail?].</td>
  </tr>
  <tr>
    <td><code>bosh_sli_run_duration_seconds{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The number of seconds the BOSH deployment SLI test suite takes to run.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_runs_total{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The total number of times the BOSH deployment SLI test suite runs. To see the failure
      rate of <code>bosh_sli_runs_total{exported_job="bosh-deployments-exporter"}</code>, divide
      the value of <code>bosh_sli_failures_total{exported_job="bosh-deployments-exporter"}</code>
      by the value of <code>bosh_sli_runs_total{exported_job="bosh-deployments-exporter"}</code>.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_duration_seconds_bucket{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The number of seconds it takes [a particular task? each task?] to run, grouped by duration.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_duration_seconds_count{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The total number of BOSH deployment SLI test suite task duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_duration_seconds_sum{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The total value of the BOSH deployment SLI test suite task duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_run_duration_seconds{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The number of seconds it takes for a particular task to run. [How do we know which task this metric refers to?]</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_runs_total{exported_job="bosh-deployments-exporter"}</code></td>
    <td>The total number of times a particular task runs [each time the whole suite runs? each time each specific SLI test within the suite runs?]. To see the failure rate of <code>bosh_sli_task_runs_total{exported_job="bosh-deployments-exporter"}</code>, divide the value of <code>bosh_sli_task_failures_total{exported_job="bosh-deployments-exporter"}</code> by the value of <code>bosh_sli_task_runs_total{exported_job="bosh-deployments-exporter"}</code>.</td>
  </tr>
  <tr>
    <td><code>bosh_sli_task_failures_total{exported_job="bosh-deployments-exporter",task="tasks"}</code></td>
    <td>The total number of times the <code>bosh tasks</code> command fails.</td>
</table>


## <a id='platform-sli'></a> Platform Metrics

Healthwatch Exporter for TAS for VMs and Healthwatch Exporter for TKGI deploy VMs that generate
metrics regarding the health of several Ops Manager and runtime components. You can use these
metrics to calculate percent availability and error budgets.

### <a id='pas-sli-exporter'></a> TAS for VMs SLI Exporter VM

Developers create and manage apps on TAS for VMs using the Cloud Foundry Command Line Interface
(cf CLI). Healthwatch Exporter for TAS for VMs deploys the TAS for VMs SLI exporter VM, `pas-sli-exporter`,
which continuously tests the functionality of the cf CLI.

The following table describes each metric the TAS for VMs SLI exporter VM generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>tas_sli_duration_seconds_bucket</code></td>
    <td>The number of seconds the TAS for VMs SLI test suite takes to run [each time the whole suite runs? each time each specific SLI test within the suite runs?], grouped by duration.</td>
  </tr>
  <tr>
    <td><code>tas_sli_duration_seconds_count</code></td>
    <td>The total number of TAS for VMs SLI test suite duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>tas_sli_duration_seconds_sum</code></td>
    <td>The total value of the TAS for VMs SLI test suite duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>tas_sli_exporter_status</code></td>
    <td>The health status of the TAS for VMs SLI exporter VM. A value of <code>1</code> indicates
      that the TAS for VMs SLI exporter VM is running and healthy.</td>
  </tr>
  <tr>
    <td><code>tas_sli_failures_total</code></td>
    <td>The total number of times that [the TAS for VMs SLI test suite fails? specific tests within the TAS for VMs SLI test suite fail?].</td>
  </tr>
  <tr>
    <td><code>tas_sli_run_duration_seconds</code></td>
    <td>The number of seconds the TAS for VMs SLI test suite takes to run.</td>
  </tr>
  <tr>
    <td><code>tas_sli_runs_total</code></td>
    <td>The total number of times the TAS for VMs SLI test suite runs. To see the failure rate
      of <code>tas_sli_runs_total</code>, divide the value of <code>tas_sli_failures_total</code>
      by the value of <code>tas_sli_runs_total</code>.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_duration_seconds_bucket</code></td>
    <td>The number of seconds it takes [a particular task? each task?] to run, grouped by duration.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_duration_seconds_count</code></td>
    <td>The total number of TAS for VMs SLI test suite task duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_duration_seconds_sum</code></td>
    <td>The total value of the TAS for VMs SLI test suite task duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_run_duration_seconds</code></td>
    <td>The number of seconds it takes for a particular task to run. [How do we know which task this metric refers to?]</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_runs_total</code></td>
    <td>The total number of times a particular task runs [each time the whole suite runs? each time each specific SLI test within the suite runs?]. To see the failure rate of <code>tas_sli_task_runs_total</code>, divide the value of <code>tas_sli_task_failures</code> by the value of <code>tas_sli_task_runs</code>.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_failures_total{task="delete"}</code></td>
    <td>The total number of times the <code>cf delete</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_failures_total{task="login"}</code></td>
    <td>The total number of times the <code>cf login</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_failures_total{task="logs"}</code></td>
    <td>The total number of times the <code>cf logs</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_failures_total{task="push"}</code></td>
    <td>The total number of times the <code>cf push</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_failures_total{task="setEnv"}</code></td>
    <td>The total number of times the <code>cf set-env</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_failures_total{task="start"}</code></td>
    <td>The total number of times the <code>cf start</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tas_sli_task_failures_total{task="stop"}</code></td>
    <td>The total number of times the <code>cf stop</code> command fails.</td>
  </tr>
</table>

### <a id='tkgi-sli-exporter'></a> TKGI SLI Exporter VM

Operators create and manage Kubernetes clusters using the TKGI Command Line Interface (TKGI
CLI). Healthwatch Exporter for TKGI deploys the TKGI SLI exporter VM, `pks-sli-exporter`, which
continuously tests the functionality of the TKGI CLI.

The following table describes each metric the TKGI SLI exporter VM generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>tkgi_sli_duration_seconds_bucket</code></td>
    <td>The number of seconds the TKGI SLI test suite takes to run [each time the whole suite runs? each time each specific SLI test within the suite runs?], grouped by duration.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_duration_seconds_count</code></td>
    <td>The total number of TKGI SLI test suite duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_duration_seconds_sum</code></td>
    <td>The total value of the TKGI SLI test suite duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_exporter_status</code></td>
    <td>The health status of the TKGI SLI exporter VM. A value of <code>1</code> indicates
      that the TKGI SLI exporter VM is running and healthy.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_failures_total</code></td>
    <td>The total number of times that [the TKGI SLI test suite fails? specific tests within the TKGI SLI test suite fail?].</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_run_duration_seconds</code></td>
    <td>The number of seconds the TKGI SLI test suite takes to run.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_runs_total</code></td>
    <td>The total number of times the TKGI SLI test suite runs. To see the failure rate of
      <code>tkgi_sli_runs_total</code>, divide the value of <code>tkgi_sli_failures_total</code>
      by the value of <code>tkgi_sli_runs_total</code>.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_duration_seconds_bucket</code></td>
    <td>The number of seconds it takes [a particular task? each task?] to run, grouped by duration.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_duration_seconds_count</code></td>
    <td>The total number of TKGI SLI test suite task duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_duration_seconds_sum</code></td>
    <td>The total value of the TKGI SLI test suite task duration metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_run_duration_seconds</code></td>
    <td>The number of seconds it takes for a particular task to run. [How do we know which task this metric refers to?]</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_runs_total</code></td>
    <td>The total number of times a particular task runs [each time the whole suite runs? each time each specific SLI test within the suite runs?]. To see the failure rate of <code>tkgi_sli_task_runs_total</code>, divide the value of <code>tkgi_sli_task_failures</code> by the value of <code>tkgi_sli_task_runs</code>.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_failures_total{task="clusters"}</code></td>
    <td>The total number of times the <code>tkgi clusters</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_failures_total{task="get-credentials"}</code></td>
    <td>The total number of times the <code>tkgi get-credentials</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_failures_total{task="login"}</code></td>
    <td>The total number of times the <code>tkgi login</code> command fails.</td>
  </tr>
  <tr>
    <td><code>tkgi_sli_task_failures_total{task="plans"}</code></td>
    <td>The total number of times the <code>tkgi plans</code> command fails.</td>
  </tr>
</table>

### <a id='cert-expiration-exporter'></a> Certificate Expiration Metric Exporter VM

Healthwatch Exporter for TAS for VMs and Healthwatch Exporter for TKGI deploy the certificate
expiration metric exporter VM, `cert-expiration-exporter`, which collects metrics regarding
when Ops Manager certificates are due to expire. For more information, see [Certificate Monitoring]
(common-configurations/certificate-monitoring.html).

The following table describes the metric the certificate expiration metric exporter VM generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>ssl_certificate_expiry_seconds{exported_instance=~".*"}</code></td>
    <td>The time in seconds until [which certificate or certificates?] expires.</td>
  </tr>
</table>

### <a id='tsdb'></a> Prometheus VM

In the **Canary URL Configuration pane** of the Healthwatch tile, you configure target URLs
to which the Blackbox Exporter in the Prometheus VM sends canary tests. Testing a canary target
URL allows you to gauge the overall health and accessibility of an app, runtime, or deployment.

On the Prometheus VM, `tsdb`, the Blackbox Exporter job, `blackbox-exporter`, generates canary
test metrics. [Is this a platform SLI or a Healthwatch component metric?]

The following table describes each metric the Blackbox Exporter in the Prometheus VM generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>probe_dns_additional_rrs</code></td>
    <td>The number of entries in the additional resource record list of the DNS server for
      the canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_dns_answer_rrs</code></td>
    <td>The number of entries in the answer resource record list of the DNS server for the
      canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_dns_authority_rrs</code></td>
    <td>The number of entries in the authority resource record list of the DNS server for the
      canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_dns_duration_seconds</code></td>
    <td>The duration of the canary test DNS request by phase.</td>
  </tr>
  <tr>
    <td><code>probe_dns_lookup_time_seconds</code></td>
    <td>The number of seconds the canary test DNS lookup takes to complete.</td>
  </tr>
  <tr>
    <td><code>probe_dns_serial</code></td>
    <td>The serial number of the DNS zone for your canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_duration_seconds</code></td>
    <td>The number of seconds the canary test takes to complete.</td>
  </tr>
  <tr>
    <td><code>probe_failed_due_to_regex</code></td>
    <td>Indicates if the canary test failed due to a regex error in the canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_http_content_length</code></td>
    <td>The length of the HTTP content response from the canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_http_duration_seconds</code></td>
    <td>The duration of the canary test HTTP request by phase, summed over all redirects.</td>
  </tr>
  <tr>
    <td><code>probe_http_last_modified_timestamp_seconds</code></td>
    <td>The last-modified timestamp for the HTTP response header in Unix time.</td>
  </tr>
  <tr>
    <td><code>probe_http_redirects</code></td>
    <td>The number of redirects the canary test goes through to reach the canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_http_ssl</code></td>
    <td>Whether the canary test used SSL for the final redirect.</td>
  </tr>
  <tr>
    <td><code>probe_http_status_code</code></td>
    <td>The status code of the HTTP response from the canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_http_uncompressed_body_length</code></td>
    <td>The length of the uncompressed response body.</td>
  </tr>
  <tr>
    <td><code>probe_http_version</code></td>
    <td>The version of HTTP the canary test HTTP response uses.</td>
  </tr>
  <tr>
    <td><code>probe_icmp_duration_seconds</code></td>
    <td>The duration of the canary test ICMP request by phase.</td>
  </tr>
  <tr>
    <td><code>probe_icmp_reply_hop_limit</code></td>
    <td><strong>If the canary test protocol is IPv6:</strong> The replied packet hop limit.
      <br>
      <strong>If the canary test protocol is IPv4:</strong> The time-to-live count.</td>
  </tr>
  <tr>
    <td><code>probe_ip_addr_hash</code></td>
    <td>The hash of the IP address of the canary target URL.</td>
  </tr>
  <tr>
    <td><code>probe_ip_protocol</code></td>
    <td>Whether the IP protocol of the canary test is IPv4 or IPv6.</td>
  </tr>
  <tr>
    <td><code>probe_ssl_earliest_cert_expiry</code></td>
    <td>The earliest SSL certificate expiration for the canary test URL in Unix time.</td>
  </tr>
  <tr>
    <td><code>probe_ssl_last_chain_expiry_timestamp_seconds</code></td>
    <td>The last SSL chain expiration for the canary test URL in Unix time.</td>
  </tr>
  <tr>
    <td><code>probe_ssl_last_chain_info</code></td>
    <td>Information about the SSL leaf certificate for the canary test URL.</td>
  </tr>
  <tr>
    <td><code>probe_success</code></td>
    <td>Whether the canary test succeeded or failed. [How is this indicated? Y/N? Yes/No? 1/2?]</td>
  </tr>
  <tr>
    <td><code>probe_tls_version_info</code></td>
    <td>The TLS version the canary test uses, or <code>NaN</code> when unknown.</td>
  </tr>
</table>

### <a id="svms"></a> Super Value Metrics (svm-forwarder)

Super value metrics (SVMs) are Healthwatch v1 metrics that the Prometheus VM in Healthwatch
generates these metrics. The SVM Forwarder VM, `svm-forwarder`, then sends these metrics back
into Loggregator so third-party nozzles can send them to external destinations, such as a remote
server or external aggregation service. For more information, see [Healthwatch Release Notes]
(release-notes.html#2-0-1). [Does this belong with the Healthwatch component metrics instead?]

The following table describes each metric the SVM Forwarder VM generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>Diego_AppsDomainSynced</code></td>
    <td>Whether Cloud Controller and Diego are in sync. [How is this indicated? Y/N? Yes/No? 1/2?]</td>
  </tr>
  <tr>
    <td><code>Diego_AvailableFreeChunksDisk</code></td>
    <td>The available free chunks of disk in all Diego Cells.</td>
  </tr>
  <tr>
    <td><code>Diego_AvailableFreeChunks</code></td>
    <td>The available free chunks of memory in all Diego Cells.</td>
  </tr>
  <tr>
    <td><code>Diego_LRPsAdded_1H</code></td>
    <td>The rate of change in running app instances in one-hour intervals.</td>
  </tr>
  <tr>
    <td><code>Diego_TotalAvailableDiskCapacity_5M</code></td>
    <td>The remaining Diego Cell disk available in all Diego Cells in five-minute intervals.</td>
  </tr>
  <tr>
    <td><code>Diego_TotalAvailableMemoryCapacity_5M</code></td>
    <td>The remaining Diego Cell memory available in all Diego Cells in five-minute intervals.</td>
  </tr>
  <tr>
    <td><code>Diego_TotalPercentageAvailableContainerCapacity_5M</code></td>
    <td>The percentage of total available container capacity in all Diego Cells in five-minute
      intervals.</td>
  </tr>
  <tr>
    <td><code>Diego_TotalPercentageAvailableDiskCapacity_5M</code></td>
    <td>The percentage of total available disk in all Diego Cells in five-minute intervals.</td>
  </tr>
  <tr>
    <td><code>Diego_TotalPercentageAvailableMemoryCapacity_5M</code></td>
    <td>The percentage of total available memory in all Diego Cells in five-minute intervals.</td>
  </tr>
  <tr>
    <td><code>Doppler_MessagesAverage_1M</code></td>
    <td>The average Doppler message rate in one-minute intervals.</td>
  </tr>
  <tr>
    <td><code>Firehose_LossRate_1H</code></td>
    <td>The log transport loss rate in one-hour intervals.</td>
  </tr>
  <tr>
    <td><code>Firehose_LossRate_1M</code></td>
    <td>The log transport loss rate in one-minute intervals.</td>
  </tr>
  <tr>
    <td><code>SyslogAgent_LossRate_1M</code></td>
    <td>The Syslog Agent loss rate in one-minute intervals.</td>
  </tr>
  <tr>
    <td><code>SyslogDrain_RLP_LossRate_1M</code></td>
    <td>The Reverse Log Proxy loss rate in one-minute intervals.</td>
  </tr>
  <tr>
    <td><code>bosh_deployment</code></td>
    <td>Represents <code>bosh_deployments_status</code> from the BOSH deployment metric exporter
      VM, which indicates whether any BOSH deployments other than the one created by the BOSH
      health metric exporter VM are running. A value of <code>1</code> indicates that other
      BOSH deployments are running on the BOSH Director.</td>
  </tr>
  <tr>
    <td><code>health_check_bosh_director_success</code></td>
    <td>Whether the BOSH SLI test suite that the BOSH health metric exporter VM ran succeeded
      or failed. A value of <code>1</code> indicates that the BOSH SLI test suite succeeded.</td>
  </tr>
  <tr>
    <td><code>health_check_CanaryApp_available</code></td>
    <td>Whether the canary app is available.</td>
  </tr>
  <tr>
    <td><code>health_check_CanaryApp_responseTime</code></td>
    <td>The response time of the canary app. [In seconds? Milliseconds?]</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_delete</code></td>
    <td>Whether the `cf delete` command succeeds or fails. [How is this indicated? Y/N? Yes/No? 1/2?]</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_login</code></td>
    <td>Whether the `cf login` command succeeds or fails.</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_logs</code></td>
    <td>Whether the `cf logs` command succeeds or fails.</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_probe_count</code></td>
    <td>The number of cf CLI health checks that Healthwatch completes in the measured time
      interval.</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_pushTime</code></td>
    <td>The amount of time it takes the cf CLI to push an app.</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_push</code></td>
    <td>Whether the `cf push` command succeeds or fails.</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_start</code></td>
    <td>Whether the `cf start` command succeeds or fails.</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_stop</code></td>
    <td>Whether the `cf stop` command succeeds or fails.</td>
  </tr>
  <tr>
    <td><code>health_check_cliCommand_success</code></td>
    <td>The overall success of the SLI tests that Healthwatch runs on the cf CLI.</td>
  </tr>
  <tr>
    <td><code>uaa_throughput_rate</code></td>
    <td>The lifetime number of requests completed by the UAA VM, emitted per UAA instance in
      TAS for VMs. This number includes health checks.</td>
  </tr>
</table>


## <a id="component-monitoring-metrics"></a> Healthwatch Component Metrics

The following metrics exist for the purpose of monitoring the Healthwatch components.

### <a id='pks-exporter'></a> TKGI Metric Exporter VM

Healthwatch Exporter for TKGI deploys a TKGI metric exporter VM, `pks-exporter`, that collects
BOSH system metrics for TKGI and converts them to a Prometheus exposition format.

The following table describes each metric the TKGI metric exporter VM collects and converts:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>healthwatch_boshExporter_ingressLatency_seconds_bucket</code></td>
    <td>The number of seconds that the TKGI metric exporter VM takes to process a batch of
      Loggregator envelopes, grouped by latency.</td>
  </tr>
  <tr>
    <td><code>healthwatch_boshExporter_ingressLatency_seconds_count</code></td>
    <td>The total number of ingress latency metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>healthwatch_boshExporter_ingressLatency_seconds_sum</code></td>
    <td>The total value of the ingress latency metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>healthwatch_boshExporter_ingress_envelopes</code></td>
    <td>The number of envelopes that the observability metrics agent receives from the TKGI
      metric exporter VM. [Meaning Loggregator? And/or something else?]</td>
  </tr>
  <tr>
    <td><code>healthwatch_boshExporter_metricConversion_seconds_bucket</code></td>
    <td>The number of seconds that the TKGI metric exporter VM takes to convert a BOSH metric
      to a Prometheus gauge, grouped by duration. [Do we know which particular metrics?]</td>
  </tr>
  <tr>
    <td><code>healthwatch_boshExporter_metricConversion_seconds_count</code></td>
    <td>The total number of conversion metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>healthwatch_boshExporter_metricConversion_seconds_sum</code></td>
    <td>The total value of the conversion metrics in all buckets.</td>
  </tr>
  <tr>
    <td><code>healthwatch_boshExporter_status</code></td>
    <td>The health status of the TKGI metric exporter VM. A value of <code>1</code> indicates
      that the TKGI metric exporter VM is running and healthy.</td>
  </tr>
</table>

### <a id='pas-exporters'></a> Healthwatch Exporter for TAS for VMs Metric Exporter VMs

Healthwatch Exporter for TAS for VMs deploys metric exporter VMs that collect metrics from
the Loggregator Firehose and convert them into a Prometheus exposition format.

Each of the following metric exporter VMs collects and converts a single metric type from the
Loggregator Firehose. The names of the metric exporter VMs correspond to the types of metrics
they collect and convert.

#### <a id='pas-exporter-counter'></a> Counter Metric Exporter VM

The counter metric exporter VM, `pas-exporter-counter`, collects counter metrics from the Loggregator
Firehose and converts them into a Prometheus exposition format.

The following table describes each metric the counter metric exporter VM collects and converts:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_counterConversion_seconds</code></td>
    <td>The number of seconds that the counter metric exporter VM takes to convert a counter
      envelope to a Prometheus counter.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_evictedMetrics</code></td>
    <td>The number of metrics that the counter metric exporter VM evicts from its cache.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_ingressLatency_seconds</code></td>
    <td>The number of seconds that the counter metric exporter VM takes to process a batch
      of Loggregator envelopes.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_ingress_envelopes</code></td>
    <td>The number of envelopes that the observability metrics agent receives from the counter metric exporter VM.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_status</code></td>
    <td>The health status of the counter metric exporter VM. A value of <code>1</code> indicates
      that the counter metric exporter VM is running and healthy.</td>
  </tr>
</table>

#### <a id='pas-exporter-gauge'></a> Gauge Metric Exporter VM

The gauge metric exporter VM, `pas-exporter-gauge`, collects gauge metrics from the Loggregator
Firehose and converts them into a Prometheus exposition format.

The following table describes each metric the gauge metric exporter VM collects and converts:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_evictedMetrics</code></td>
    <td>The number of metrics that the gauge metric exporter VM evicts from its cache.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_gaugeConversion_seconds</code></td>
    <td>The number of seconds that the gauge metric exporter VM takes to convert a gauge envelope
      to a Prometheus gauge.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_ingressLatency_seconds</code></td>
    <td>The number of seconds that the gauge metric exporter VM takes to process a batch of
      Loggregator envelopes.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_ingress_envelopes</code></td>
    <td>The number of envelopes that the observability metrics agent receives from the gauge metric exporter VM.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_status</code></td>
    <td>The health status of the gauge metric exporter VM. A value of <code>1</code> indicates
      that the gauge metric exporter VM is running and healthy.</td>
  </tr>
</table>

#### <a id='pas-exporter-timer'></a> Timer Metric Exporter VM

The timer metric exporter VM, `pas-exporter-timer`, collects timer metrics from the Loggregator
Firehose and converts them into a Prometheus exposition format.

The following table describes each metric the timer metric exporter VM collects and converts:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_evictedMetrics</code></td>
    <td>The number of metrics that timer metric exporter VM evicts from its cache.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_ingressLatency_seconds</code></td>
    <td>The number of seconds that timer metric exporter VM takes to process a batch of Loggregator
      envelopes.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_ingress_envelopes</code></td>
    <td>The number of envelopes that the observability metrics agent receives from the timer metric exporter VM.</td>
  </tr>
  <tr>
    <td><code>healthwatch_tasExporter_status</code></td>
    <td>The health status of the timer metric exporter VM. A value of <code>1</code> indicates
      that the timer metric exporter VM is running and healthy.</td>
  </tr>
</table>

### <a id="prometheus-exposition"></a> Prometheus Exposition Endpoint

Most of the metric exporter VMs generate metrics concerning how the Prometheus VM interacts
with the `/metrics` endpoint on each metric exporter VM.

The following table describes each metric the `/metrics` endpoint on each metric exporter VM
generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>healthwatch_prometheusExpositionLatency_seconds</code></td>
    <td>The number of seconds that the metric exporter VM takes to render a Prometheus scrape
      page.</td>
  </tr>
  <tr>
    <td><code>healthwatch_prometheusExposition_expiredMetrics</code></td>
    <td>The number of metrics that the metric exporter VM evicts from its cache.</td>
  </tr>
  <tr>
    <td><code>healthwatch_prometheusExposition_histogramMapConversion</code></td>
    <td>The number of [seconds? milliseconds?] that the metric exporter VM takes to convert histogram collection to a map.</td>
  </tr>
  <tr>
    <td><code>healthwatch_prometheusExposition_metricMapConversion</code></td>
    <td>The number of [seconds? milliseconds?] that the metric exporter VM takes to convert metrics collection to a map.</td>
  </tr>
  <tr>
    <td><code>healthwatch_prometheusExposition_metricSorting</code></td>
    <td>The number of [seconds? milliseconds?] that the metric exporter VM takes to sort metrics when rendering Prometheus exposition.</td>
  </tr>
</table>

### <a id="svm-forwarder"></a> SVM Forwarder Monitoring Metrics (svm-forwarder)

The SVM Forwarder sends Healthwatch v1 SVMs to the Loggregator Firehose for the Prometheus
VM that exists in an external monitoring service to scrape. For more information, see [2.0.1]
(release-notes.html#2-0-1) in _Healthwatch Release Notes_.

The following table describes each metric the SVM Forwarder VM generates:

<table>
  <tr>
    <th>Metric</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><code>failed_scrapes_total</code></td>
    <td>The total number of failed scrapes for the target <code>source_id</code>.</td>
  </tr>
  <tr>
    <td><code>last_total_attempted_scrapes</code></td>
    <td>The total number of attempted scrapes during the most recent round of scraping.</td>
  </tr>
  <tr>
    <td><code>last_total_failed_scrapes</code></td>
    <td>The total number of failed scrapes during the most recent round of scraping.</td>
  </tr>
  <tr>
    <td><code>last_total_scrape_duration</code></td>
    <td>The time in milliseconds to scrape all targets during the most recent round of scraping.</td>
  </tr>
  <tr>
    <td><code>scrape_targets_total</code></td>
    <td>The total number of scrape targets identified from the configuration file for the Prometheus
      VM.</td>
  </tr>
</table>
