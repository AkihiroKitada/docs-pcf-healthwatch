---
title: Installing Healthwatch
owner: Healthwatch
---

This topic describes how to install and configure Healthwatch for Pivotal Cloud Foundry (PCF). 

## Install Healthwatch

1. Download the product file from [Healthwatch](https://network.pivotal.io/products/p-healthwatch/).

1. Navigate to the Ops Manager Installation Dashboard and click **Import a Product** to upload the product file.

1. Under the **Import a Product** button, click **+** next to the version number of Healthwatch.
This adds the tile to your staging area.

<p class="note"><strong>Note:</strong> Installing using Platform Automation </p>

The following config file for the `download-product` task will work to fetch the **Healthwatch** tile (without getting the exporters):

```yaml
---
pivnet-api-token: token
pivnet-file-glob: "Healthwatch-view-[^pks|pas]*.pivotal"
pivnet-product-slug: Healthwatch_view_pcf
product-version-regex: "0.4.*"
```

##  Configure the Healthwatch Tile

To configure the Healthwatch tile, perform the following steps:

1. Click the **Healthwatch** tile on the Ops Manager Installation Dashboard.
1. Navigate to **Assign AZs and Networks** and do the following:
    1. Select an Availability Zone (AZ) for placing singleton jobs.
    1. Select one or more AZs for balancing other jobs.
    1. Select **Network** for installing Healthwatch.
    1. Click **Save**.

1. Navigate to **Time series database(TSDB) Configuration** and do the following:
    1. Optional: Modify the **Scrape Interval** as desired. This controls the frequency at which the TSDB scrapes its targets for metrics.
    1. Optional: Add additional jobs to the `Additional Scrape Config Jobs`.  This entry section allows you to add jobs to the TSDB.yml configuration
       file.
       * The first field, **TSDB Scrape job**  takes a YAML formatted job in the format specified
       by [TSDB](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config)
](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config) . This job can use any of the properties
       defined by Prometheus itself except for the`tls_config` property.  The entries for that can be filled in below. Note that this box takes a single
       scrape job.  The job should not be prepended with the YAML array *-*.
       * Optional: **TLS Config Certificate Authority** This field takes a CA Certificate that will end up in the **ca_file** property of the **tls_config**.
       * Optional: **TLS Config Certificate and Private Key** This field takes a Certificate and Private key.  These properties will end up in the **cert_file**
       and **key_file** properties of the **tls_config**
       * Optional: **TLS Config Server Name** This field takes a string server name that will end up in the **server_name** field of the **tls_config**
   1. If using `om` to configure the tile, you will want a configuration like the following:
```yaml
{% include "product-config.yml" %}
```
1. Navigate to **Health Check** and do the following:

  1. Enter **Ops Manager URL**. The URL should include the protocol.  This URL must be reachable from a `cf pushed` application.
  1. In **BOSH Health Check Availability Zone**, select an AZ for the BOSH Health Check VM.
    <p class="note"><strong>Note</strong>: On Azure environments, this dropdown is null because Azure does not support AZs.</p>

  1. In **BOSH Health Check VM Type**, select a VM type for the BOSH Health Check VM. The recommended VM type is **small**. The VM resources should include at least:
    - 1 CPU
      - 8 GB Disk
      - 1 GB RAM  
  If you have add-ons installed, you may need to increase the RAM of the BOSH Health Check VM type. For an example of add-on memory requirements, see the [Prerequisites](https://docs.pivotal.io/addon-antivirus/1-4/install.html#prereqs) section of the ClamAV add-on documentation.
  1. Optionally, you can also enable the BOSH Deployment Checker.  This adds context to the Pivotal Healthwatch UI graphs of when BOSH deployments have occurred.
       1. Select **Enable** in the `Bosh Deployment Checker` section.
       1. Enter a BOSH UAA client and secret with an authority of `bosh.read`.
       <p class="note"><strong>Note:</strong> In previous versions of Pivotal Healthwatch, the BOSH Deployment Checker used the BOSH Director admin credentials as default values. As of v1.3, the BOSH Deployment Checker defaults to disabled until configured.</p>
            1. Follow the instructions for [Creating UAA Clients for BOSH Director](https://docs.pivotal.io/pivotalcf/2-3/customizing/opsmanager-create-bosh-client.html) to target the BOSH UAA and log in with an admin credential. Ensure that you are targeting the BOSH UAA and not Ops Manager or PAS UAA. If your BOSH Director is SSO-enabled, run the following command to log into the UAA:
            <pre class="terminal">uaac token sso get BOSH-DIRECTOR-UAA-LOGIN-CLIENT-USERNAME</pre>
            1. Create a UAA Client for the Healthwatch BOSH task check using the following command:
            <pre class="terminal">uaac client add CLIENT-NAME --authorized\_grant\_types client\_credentials --authorities bosh.read --secret CLIENT-SECRET</pre>
  1. Click **Save**.

1. Navigate to **UI Configuration** and do the following:
    1. Optional: If you configured Grafana to be accessible from outside the BOSH network, you may want to specify the
       `Root URL For the UI`. This should be set to the full URL used to access Grafana from a web browser.
       This is important if you use Google or GitHub OAuth authentication (for the callback URL to be correct).
    1. Optional: Enter a list of **Static IPs for the UI VM(s)**.  These IPs should be comma separated and be 
       valid static IPs from the IAAS for the network on which the tile is installed.
    1. Optional: **Enable UI Login Form**  Disabling this option will prevent anyone, including the admin user, from logging in with Basic Authentication
    1. Optional: **Select an authentication mechanism for the UI**.  Options include Basic, Generic OAuth(UAA, Github, etc) or LDAP. See [Grafana Authentication](grafana-authentication.html) for detailed configurations.
    1. Optional: **Enable SMTP for Grafana Alerts** Enabling this option will allow Grafana to send emails for alerts that are configured through the dashboard.
       For individual field references, see [Grafana SMTP Configuration](https://grafana.com/docs/installation/configuration/#smtp).
1. Navigate to **Canary URL Configuration** and do the following:
    1. Optional: Enter **Exporter Port** for the process to listen on. It is only necessary to change from the default port if
       you have a port conflict on the TSDB VM.  The port is defaulted to `9115`.
    1. Optional: Enter a list of **Target URLs**.  [The Blackbox Exporter](https://github.com/prometheus/blackbox_exporter) will run continuous probe tests
       on the URLs and record the results in the TSDB.  These probe tests are useful for generating SLI type metrics. There are no additional scrape configuration jobs necessary
       for the URLs entered here. They will be automatically added to the TSDB scrape jobs.

### PKS Cluster Discovery Configuration
To configure PKS cluster discovery:

1. Navigate to **PKS Cluster Discovery Configuration** and do the following:
    1. Select **Enable**
    1. Optional: Enter **Scrape Port** for the process to listen on.
    1. Enter the PKS API Address. This should be the API address you entered in **Ops Manager >Enterprise PKS >PKS API >API Hostname (FQDN)**. For example, `api.pks.example.com`.
    1. Enter the PKS UAA Client and Secret. You can use the PKS management admin client credential, where the client is `admin` and the secret can be found in **Ops Manager >Enterprise PKS>Credentials>Pks Uaa Management Admin Client**.
       Otherwise a separete UAA client with full access to the PKS API can be created and entered here.
    1. Optional: Enter **Test Frequency** to configure the interval in seconds how frequent the PKS SLI test runs. The PKS SLI test monitors the health of PKS API by logging into the API server, listing all clusters, and logging out the API server.
    1. Enter the PKS API Certificate Authority. This is required if the PKS API is using a self-signed certificate. Alternatively, `PKS API Skip SSL Validation` can be selected, but it is not recommended for production use.
    1. At this point you have finished the configuration needed in Healthwatch tile, there are one additional configuration needed in `Enterprise PKS` tile to have the metrics pulling from the clusters correctly.
1. Go to `Enterprise PKS` tile and for each plan you want to monitoring:
    1. Navigate to the plan you want to monitor. For example, `Plan 2`.
    1. Scroll to `(Optional) Add-ons - Use with caution`.
    1. Paste the following yaml snippet to the text box to configure roles required to scrape metrics from the clusters:

```yaml
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
 name: healthwatch
rules:
 - resources:
     - pods/proxy
     - pods
     - nodes
     - nodes/proxy
     - namespace/pods
     - endpoints
     - services
   verbs:
     - get
     - watch
     - list
   apiGroups:
     - ""
 - nonResourceURLs: ["/metrics"]
   verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
 name: healthwatch
roleRef:
 apiGroup: ""
 kind: ClusterRole
 name: healthwatch
subjects:
 - apiGroup: ""
   kind: User
   name: healthwatch
   namespace: pks-system
```

If there are already other API resource definitions in the text filed, simply append the above snippet to the end, followed by a newline character.
<p class="note"><strong>Note:</strong> During Apply Changes, Make sure **Enterprise PKS>Errands>Upgrade all clusters errand is enabled to have the addon resources propagated to on demand clusters.</p>

<p class="note"><strong>Note:</strong> Installing using Platform Automation </p>
When installing **Healthwatch PAS Exporter** or **Healthwatch PKS Exporter** on the same foundation as
**Healthwatch**, there is no need to manually configure a scrape job for them. These exporters are automatically discovered and scraped.
This section is for adding additional custom scrape jobs or to scrape exporters installed on different foundations.

<p class="note warning"><strong>Warning: </strong>Job Names</p>

When configuring custom scrape jobs, it is recommended that you avoid using the following job names:

      * `Healthwatch-view-pas-exporter`
      * `Healthwatch-view-pks-exporter`
      * `tsdb`
      * `ui`
      * `pks-master-kube-scheduler`
      * `pks-master-kube-controller-manager`

1. Return to the Ops Manager Installation Dashboard and click **Apply Changes**.

1. In order to access Grafana within **Healthwatch** an external IP address for the `ui` VM is needed along with allowing traffic to the VM on port 3000. A native IaaS load balancer can also be used. 

##  (Optional) Backing Up Healthwatch

Healthwatch supports [Bosh Backup and Restore](https://docs.pivotal.io/pivotalcf/2-4/customizing/backup-restore/index.html) functionality.
We recommend running nightly backups via a Concourse pipeline job like the one below:

```yaml
---
resource_types:
  - name: gcs-resource
    type: docker-image
    source:
      repository: frodenas/gcs-resource

  - name: pivnet
    type: docker-image
    source:
      repository: pivotalcf/pivnet-resource
      tag: latest-final

resources:
  - name: bbr-release
    type: pivnet
    source:
      api_token: ((pivnet-refresh-token))
      product_slug: p-bosh-backup-and-restore

  - name: bbr-pipeline-tasks-repo
    type: git
    source:
      uri: https://github.com/pivotal-cf/bbr-pcf-pipeline-tasks.git
      branch: master
      tag_filter: v1.0.0

  - name: bbr-docker
    type: docker-image
    source:
      repository: cloudfoundrylondon/bbr-pipeline
      tag: final

  - name: nightly
    type: time
    source:
      interval: 24h
      start: 22:00
      stop: 00:00
      location: America/Denver

  - name: rv-backup-bucket
    type: gcs-resource
    source:
      bucket: ((gcs-bucket-name))
      json_key: ((service-account-json))
      regexp: ((gcs-directory))/rv-backup-(.*).tar

jobs:
  - name: trigger-backup
    plan:
      - put: nightly

  - name: nightly-backup
    plan:
      - aggregate:
        - get: nightly
          trigger: true
        - get: bbr-docker
        - get: bbr-release
        - get: bbr-pipeline-tasks-repo
      - task: extract-binary
        file: bbr-pipeline-tasks-repo/tasks/extract-bbr-binary/task.yml
      - task: run-backup
        image: bbr-docker
        config:
          platform: linux

          inputs:
            - name: binary
            - name: bbr-pipeline-tasks-repo

          outputs:
            - name: rv-backup-artifact

          params:
            OPSMAN_URL: ((opsman-url))
            OPSMAN_USERNAME: ((opsman-user.username))
            OPSMAN_PASSWORD: ((opsman-user.password))
            OPSMAN_PRIVATE_KEY: ((ops-man-ssh-key.private_key))

          run:
            path: /bin/bash
            args:
              - -c
              - |
                #!/usr/bin/env bash

                set -eu

                scripts="${PWD}/bbr-pipeline-tasks-repo/scripts"

                export CLIENT_ID=
                # shellcheck disable=SC1090
                source "${scripts}/export-director-metadata"

                om_cmd curl -p /api/v0/deployed/products > deployed_products.json
                DEPLOYMENT_NAME=$(jq -r '.[] | select(.type == "p-Healthwatch-view") | .guid' "deployed_products.json")
                export DEPLOYMENT_NAME

                pushd rv-backup-artifact
                  ${scripts}/deployment-backup
                  tar -cvf rv-backup-$(date +%Y.%m.%d.%H.%M.%S).tar -- *
                popd

      - put: rv-backup-bucket
        params:
          file: rv-backup-artifact/rv-backup-*.tar
```

##  (Optional) Restoring Healthwatch from a BBR Backup
If you are running nightly backups, you have the ability to restore the Prometheus and Grafana data using Bosh Backup and Restore.
Be aware that this will delete any existing data on all Prometheus and Grafana VMs and restore them to when the backup was taken.

To restore, run the following commands:

```bash
mkdir -p $PATH_TO_DEPLOYMENT_BACKUP
tar xvf rv-backup-*.tar -C $PATH_TO_DEPLOYMENT_BACKUP
bbr deployment \
  --target $BOSH_TARGET \
  --username $BOSH_CLIENT \
  --password $BOSH_PASSWORD \
  --deployment $Healthwatch_VIEW_DEPLOYMENT_NAME \
  --ca-cert $PATH_TO_BOSH_SERVER_CERTIFICATE \
  restore \
  --artifact-path $PATH_TO_DEPLOYMENT_BACKUP
```
