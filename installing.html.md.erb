---
title: Installing Healthwatch
owner: Healthwatch
---

This topic describes how to install and configure Healthwatch.

## Install Healthwatch

1. Download the product file from [Healthwatch](https://network.pivotal.io/products/p-healthwatch/).

1. Navigate to the Ops Manager Installation Dashboard and click **Import a Product** to upload the product file.

1. Under the **Import a Product** button, click **+** next to the version number of Healthwatch.
This adds the tile to your staging area.

<p class="note">
    <strong>Note:</strong>
    Installing using Platform Automation

    <br/><br/>

    The following config file for the <code>download-product</code> task
    will work to fetch the Healthwatch tile (without getting the exporters):
</p>

```yaml
---
pivnet-api-token: token
pivnet-file-glob: "healthwatch-[^pas|pks].*pivotal"
pivnet-product-slug: p-healthwatch
product-version-regex: 2\.0.*
```

<p class="note">
    <strong>Note:</strong>
    When Healthwatch Tanzu Application Service Exporter
    or Healthwatch PKS Exporter is on the same foundation as Healthwatch,
    there is no need to manually configure a scrape job for them.
    These exporters are automatically discovered and scraped.
    This section is for adding additional custom scrape jobs or to scrape exporters installed on different foundations.
</p>

##  Configure the Healthwatch Tile

To configure the Healthwatch tile, perform the following steps:

1. Click the **Healthwatch** tile on the Ops Manager Installation Dashboard.
1. Navigate to **Assign AZs and Networks** and do the following:
    1. Select an Availability Zone (AZ) for placing singleton jobs.
    1. Select one or more AZs for balancing other jobs.
    1. Select **Network** for installing Healthwatch.
    1. Click **Save**.

1. Navigate to **Time series database (TSDB) Configuration** and do the following:
    1. Optional: Modify the **Scrape Interval** as desired. This controls the frequency at which the TSDB scrapes its targets for metrics. Healthwatch recommends using a 15 seconds scraping interval to provide balance between metric detail and storage consumption.
    1. Optional: Add additional jobs to the `Additional Scrape Config Jobs`.  This entry section allows you to add jobs to the TSDB.yml configuration
        file.
        * The first field, **TSDB Scrape job**  takes a YAML formatted job in the format specified
            by [TSDB](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config) This job can use any of the properties
            defined by TSDB itself except for the `tls_config` property.  The entries for that can be filled in below. Note that this box takes a single
            scrape job.  The job should not be prepended with the YAML array `-`. An example of the scrape config should look like:

            ```yaml
            job_name: foundation1
            metrics_path: /metrics
            scheme: https
            static_configs:
             - targets:
               - "1.2.3.4:9090"
               - "5.6.7.8:9090"
            ```
        * Optional: **TLS Config Certificate Authority** This field takes a CA Certificate that will end up in the **ca_file** property of the **tls_config**.
        * Optional: **TLS Config Certificate and Private Key** This field takes a Certificate and Private key.  These properties will end up in the **cert_file**
            and **key_file** properties of the **tls_config**
        * Optional: **TLS Config Server Name** This field takes a string server name that will end up in the **server_name** field of the **tls_config**

    1. If using `om` to configure the tile, you will want a configuration like the following:

        <%= partial 'snippets/scrape_config.md' %>
    1. Optional: Change the **Chunk Size (Disk) MB** for calculating the available disk chunks super value metric (SVM). Healthwatch dashboards do not rely on this parameter at all, the purpose of the option is for legacy firehose integration to generate the Diego_AvailableFreeChunksDisk metric only. The legacy firehose integration calculates the metric using Prometheus Query Language (PromQL) and puts them back to the loggregator system to have the calculated metric consumable by third party nozzles.
    1. Optional: Change the **Chunk Size (Memory) MB** for calculating the available memory chunks SVM. The purpose of this option is the same as above.

<p class="note warning">
    <strong>Warning: </strong>
    Job Names

    <br/><br/>

    When configuring custom scrape jobs,
    it is recommended that you avoid using the following job names:
</p>

* `Healthwatch-view-pas-exporter`
* `Healthwatch-view-pks-exporter`
* `tsdb`
* `grafana`
* `pks-master-kube-scheduler`
* `pks-master-kube-controller-manager`

1. Navigate to **Grafana Configuration** and do the following:
    1. Optional: If you configured Grafana to be accessible from outside the BOSH network, you may want to specify the
        `Root URL for Grafana`. This should be set to the full URL used to access Grafana from a web browser.
        This property must be set for Generic OAuth or UAA to redirect correctly. It is also used to generate links to Grafana in alert messages.
        <p class="note"><strong>Note:</strong> The URL you enter here needs to be configured in your DNS provider to point to the public IP address of the Grafana VM, or the public IP address of the load balancer that sits in from of the Grafana VMs. The IP address to Grafana can be obtained after Apply Changes.</p>
        <p class="note"><strong>Note:</strong> Proxy settings are only required if you are deploying Healthwatch in an air-gapped environment and want to set up alert channels to external addresses. For example, attempting to send alerts to the external Slack webhook.</p>
    1. Optional: Configure the proxy setting for Grafana.
        1. Select **Enabled**
        1. Enter the HTTP proxy server address in **HTTP Proxy for Grafana**.
            This will be used as the proxy URL for HTTP and HTTPS requests
            unless overridden by **HTTPS Proxy for Grafana** or **No Proxy for Grafana**.
        1. Enter the HTTPS proxy server address in **HTTPS Proxy for Grafana**.
            This will be used as the proxy URL for HTTPS requests unless overridden by **No Proxy for Grafana**.
        1. Enter the list of the hosts that should be excluded from proxying in **No Proxy for Grafana**.
            This should be a comma separated list. VMware recommends to include “*.bosh” and the ip range for the internal networks
            so that the time series database can still be accessed without going though the proxy.
            For example: “*.bosh,10.0.0.0/8,*.example.com” will configure grafana to access all bosh dns addresses,
            10.0.0.0/8 internal addresses and *.example.com directly without going though the proxy.
    1. Optional: Enter a list of **Static IPs for the Grafana VM(s)**.  These IPs should be comma separated and be
        valid static IPs from the IAAS for the network on which the tile is installed.
    1. Optional: **Enable Grafana Login Form**  Disabling this option will prevent anyone, including the admin user, from logging in with Basic Authentication
    1. Optional: **Use Indicator Protocol Generated Dashboards**
        Checking this option will enable generation of dashboards
        based on indicator documents.
        <p class="note">
            <strong>Note:</strong>
            This assumes that the Monitoring Indicator Protocol tile
            is also installed on this foundation.
            For more information,
            visit the product page
            <a href="https://network.pivotal.io/products/indicator-protocol/">
              here
            </a>.
        </p>
    1. Optional: **Select an authentication mechanism for the Grafana**.  Options include Basic, Generic OAuth(UAA, Github, etc) or LDAP. See [Grafana Authentication](common-configurations/grafana-authentication.html) for detailed configurations.
    1. Optional: **Enable SMTP for Grafana Alerts** Enabling this option will allow Grafana to send emails for alerts that are configured through the dashboard.
        For individual field references, see [Grafana SMTP Configuration](https://grafana.com/docs/installation/configuration/#smtp).

1. Navigate to **Canary URL Configuration** and do the following:
    <p class="note">
        <strong>Note:</strong>
        Canary applications are those applications you "send in first"
        and are an indicator of the overall health of your platform.
        If a canary app is down,
        there is probably an issue with the platform.
        For example, Apps Manager would be a good candidate for a canary url.
    </p>

    1. Optional: Enter **Exporter Port** for the process to listen on. It is only necessary to change from the default port if
        you have a port conflict on the TSDB VM. The port is defaulted to `9115`.
    1. Optional: Enter a list of **Target URLs**. [The Blackbox Exporter](https://github.com/prometheus/blackbox_exporter) will run continuous probe tests
        on the URLs and record the results in the TSDB.  These probe tests are useful for generating SLI type metrics. There are no additional scrape configuration jobs necessary
        for the URLs entered here. They will be automatically added to the TSDB scrape jobs.

## PKS Cluster Discovery Configuration

PKS Cluster Discovery enables users to detect and configure clusters created by the PKS API.

To configure PKS cluster discovery:

<p class="note"><strong>Note:</strong> PKS Cluster Discovery only applies for foundations running PKS</p>

1. Navigate to **PKS Cluster Discovery Configuration** and do the following:
    1. Select **Enabled**
    1. Optional: Enter **Scrape Port** for the process to listen on.
    1. Enter the PKS API Address. This should be the API address you entered in **Ops Manager >Enterprise PKS >PKS API >API Hostname (FQDN)**. For example, `api.pks.example.com`.
    1. Enter the PKS UAA Client and Secret. You can use the PKS management admin client credential, where the client is `admin` and the secret can be found in **Ops Manager >Enterprise PKS>Credentials>Pks Uaa Management Admin Client**.
        Otherwise a separate UAA client with full access to the PKS API can be created and entered here.
    1. Optional: Enter **Test Frequency** to configure the interval in seconds how frequent the PKS SLI test runs. The PKS SLI test monitors the health of PKS API by logging into the API server, listing all clusters, and logging out the API server.
    1. Enter the PKS API Certificate Authority. This is required if the PKS API is using a self-signed certificate. Alternatively, `PKS API Skip SSL Validation` can be selected, but it is not recommended for production use.
    1. At this point you have finished the configuration needed in Healthwatch tile, there are one additional configuration needed in `Enterprise PKS` tile to have the metrics pulling from the clusters correctly.

1. Navigate to **Enterprise PKS** tile
    1. Navigate to **Host Monitoring**
    1. Check **Include etcd metrics**
    1. Fill in **Setup Telegraf Outputs** with the following:

        ```toml
        [[outputs.prometheus_client]]
          ## Address to listen on.
          listen = ":10200"
        ```
        <p class="note">
            <strong>Note:</strong>
            It is important to set this port specifically to <code>10200</code>
            because that is what the scrape config expects.
        </p>

1. Go to **Enterprise PKS** tile and for each plan you want to monitor:
    1. Navigate to the plan you want to monitor. For example, **Plan 2**.
    1. Scroll to **(Optional) Add-ons - Use with caution**.
    1. Paste the following yaml snippet to the text box to configure roles required to scrape metrics from the clusters:

        <%= partial 'snippets/cluster_scraping_config.md' %>
        If there are already other API resource definitions in the text field,
        simply append the above snippet to the end,
        followed by a newline character.

        <p class="note">
            <strong>Note:</strong>
            During Apply Changes,
            make sure <code>Enterprise PKS > Errands > Upgrade all clusters</code> errand
            is enabled to have the add-on resources propagated to on demand clusters.
        </p>

    1. Return to the Ops Manager Installation Dashboard and click Apply Changes.

    1. In order to access Grafana within Healthwatch,
       an external IP address for the **Grafana** VM is needed
       along with allowing traffic to the VM on port 443 or 80,
       depending on whether you configured a certificate
       in the **Enable HTTPS by providing certificates** field
       under **Grafana Configuration** in the tile configuration.
       A native IaaS load balancer can also be used.

##  (Optional) Backing Up Healthwatch

Healthwatch supports [Bosh Backup and Restore](https://docs.pivotal.io/pivotalcf/2-4/customizing/backup-restore/index.html) functionality.
VMware recommends running nightly backups via a Concourse pipeline job like the one below:

<%= partial 'snippets/backup_job' %>

##  (Optional) Restoring Healthwatch from a BBR Backup
If you are running nightly backups, you have the ability to restore the TSDB and Grafana data using Bosh Backup and Restore.
Be aware that this will delete any existing data on all TSDB and Grafana VMs and restore them to when the backup was taken.

To restore, run the following commands:

```bash
mkdir -p $PATH-TO-DEPLOYMENT-BACKUP
tar xvf rv-backup-*.tar -C $PATH-TO-DEPLOYMENT-BACKUP
bbr deployment \
  --target $BOSH-TARGET \
  --username $BOSH-CLIENT \
  --password $BOSH-PASSWORD \
  --deployment $Healthwatch-VIEW-DEPLOYMENT-NAME \
  --ca-cert $PATH-TO-BOSH-SERVER-CERTIFICATE \
  restore \
  --artifact-path $PATH-TO-DEPLOYMENT-BACKUP
```

Where:

* `PATH-TO-DEPLOYMENT-BACKUP` is the filepath to your BBR backup.
* `BOSH-TARGET` is your Bosh Director
* `BOSH-CLIENT` is your Bosh username
* `BOSH-PASSWORD` is Bosh user password
* `Healthwatch-VIEW-DEPLOYMENT-NAME` is the name of your Healthwatch deployment
* `PATH-TO-BOSH-SERVER-CERTIFICATE` is the Bosh Director CA