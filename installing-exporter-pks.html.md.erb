---
title: Installing Healthwatch Exporter for TKGI
owner: Healthwatch
---

<strong><%= modified_date %></strong>

This topic describes how to install and configure the Healthwatch Exporter for Tanzu Kubernetes
Grid Integrated (TKGI).


## <a id='overview'></a> Overview of Healthwatch Exporter for TKGI

When installed on a foundation you want to monitor, the Healthwatch Exporter for TKGI tile
deploys metric exporter VMs to process service level indicators (SLIs) related to the health
of your TKGI deployment.

The Prometheus VM that exists within your metrics monitoring system then scrapes the Prometheus
exposition endpoints on the metric exporter VMs and imports those metrics into your monitoring
system. This monitoring system can be the Healthwatch tile installed on your Ops Manager foundation
or a service or database located outside your Ops Manager foundation.


## <a id='procedure'></a> Installation Procedure

To install and configure the Healthwatch Exporter for TKGI tile:

1. Install the Healthwatch Exporter for TKGI tile in the Ops Manager Installation Dashboard.
For more information, see [Install the Healthwatch Exporter for TKGI Tile](#install) below.

1. Configure the Healthwatch Exporter for TKGI tile. For more information, see [Configure the
Healthwatch Exporter for TKGI Tile](#configure) below.

1. Deploy the Healthwatch Exporter for TKGI tile. For more information, see [Deploy Healthwatch
Exporter for TKGI](#apply-changes) below.

1. Once you have finished installing and configuring Healthwatch Exporter for TKGI, configure
a scrape job for Healthwatch Exporter for TKGI in the Prometheus VM that exists within your
monitoring system. For more information, see [Configure a Scrape Job for Healthwatch Exporter
for TKGI](#scrape-job-config) below.


## <a id='install'></a> Install the Healthwatch Exporter for TKGI Tile

There are two ways to install the Healthwatch Exporter for TKGI tile:

* Download the Healthwatch Exporter for TKGI tile from VMware Tanzu Network. For more information,
see [Install Healthwatch Exporter for TKGI from VMware Tanzu Network](#pivnet) below.

* Fetch the tile using Platform Automation. For more information, see [Install Healthwatch
Exporter for TKGI with Platform Automation](#platform-automation) below.

### <a id='pivnet'></a> Install the Healthwatch Exporter for TKGI from VMware Tanzu Network

If you are manually configuring the Healthwatch Exporter for TKGI tile, install the Healthwatch
Exporter for TKGI tile from VMware Tanzu Network.

To install the Healthwatch Exporter for TKGI tile from VMware Tanzu Network:

1. Navigate to the [Healthwatch](https://network.pivotal.io/products/p-healthwatch/) page on
VMware Tanzu Network.

1. From the **Releases** dropdown, select the version you want to install.

1. Click **Healthwatch Exporter for TKGI** to download the Healthwatch Exporter for TKGI `.pivotal`
file.

1. Navigate to the Ops Manager Installation Dashboard.

1. Under the **Import a Product** button, click the **+** icon next to the Healthwatch Exporter
for TKGI listing to add the tile to your staging area. For more information, see [Adding and
Deleting Products](https://docs.pivotal.io/ops-manager/install/add-delete.html) in the Ops
Manager documentation.

### <a id='platform-automation'></a> Install Healthwatch Exporter for TKGI with Platform Automation

If you want to use automation scripts to configure the Healthwatch Exporter for TKGI tile,
use Platform Automation to fetch the Healthwatch Exporter for TKGI tile using a configuration
file.

To fetch the Healthwatch Exporter for TKGI tile using a configuration file:

1. Create a configuration file for the `download-product` task of your automated pipeline.
The following configuration file fetches the Healthwatch Exporter for TKGI tile from VMware
Tanzu Network:

    ```
    ---
    pivnet-api-token: token
    pivnet-file-glob: "healthwatch-pks-*.pivotal"
    pivnet-product-slug: p-healthwatch
    product-version-regex: "0.4.*"
    ```
    For more information, see [Download](https://docs.pivotal.io/platform-automation/v5.0/how-to-guides/adding-a-product.html#download)
    in _Extending a Pipeline to Install a Product_ in the Platform Automation documentation.

1. Upload and stage the Healthwatch Exporter for TKGI tile to the Ops Manager Installation
Dashboard. For more information, see [Upload and Stage](https://docs.pivotal.io/platform-automation/v5.0/how-to-guides/adding-a-product.html#upload-and-stage)
in _Extending a Pipeline to Install a Product_ in the Platform Automation documentation.

For more information about adding a product to the Ops Manager Installation Dashboard through
Platform Automation, see [Extending a Pipeline to Install a Product](https://docs.pivotal.io/platform-automation/v5.0/how-to-guides/adding-a-product.html)
in the Platform Automation documentation.


## <a id='configure'></a> Configure the Healthwatch Exporter for TKGI Tile

This section describes how to configure the Healthwatch Exporter TKGI tile.

To configure the Healthwatch Exporter TKGI tile:

<p class='note'><strong>Note:</strong> If you want to quickly deploy the Healthwatch Exporter
  for TKGI tile to ensure that it deploys successfully before you fully configure it, you only
  need to configure the <strong>Assign AZ and Networks</strong> and <strong>BOSH Health Exporter
  Configuration</strong> panes.</p>

1. Click the **Healthwatch Exporter for TKGI** tile.

1. Assign jobs to your Availability Zones (AZs) and networks. For more information, see [Assign
AZs and Networks](#az) below.

1. (Optional) Configure the **TKGI Exporter Configuration** pane. For more information, see
[(Optional) Configure TKGI and Certificate Expiration Metric Exporter VMs](#exporter-config)
below.

1. (Optional) Configure the **TKGI SLI Exporter Configuration** pane. For more information,
see [(Optional) Configure TKGI SLI Exporter VMs](#sli-config) below.

1. Configure the **BOSH Health Exporter Configuration** pane. For more information, see [Configure
the BOSH Health Metric Exporter VM](#bosh-exporter) below.

1. (Optional) Configure the **Bosh Deployments Exporter Configuration** pane. For more information,
see [(Optional) Configure the BOSH Deployment Metric Exporter VM](#bosh-deployments) below.

1. (Optional) Configure the **Errands** pane. For more information, see [(Optional) Configure
Errands](#errands) below.

1. (Optional) Configure the **Syslog** pane. For more information, see [(Optional) Configure
Syslog](#syslog) below.

1. (Optional) Configure the **Resource Config** pane. For more information, see [(Optional)
Configure Resources](#resource-config) below.

### <a id='az'></a> Assign AZs and Networks

In the **Assign AZ and Networks** pane, you assign jobs to your AZs and networks.

To configure the **Assign AZ and Networks** pane:

1. Select **Assign AZs and Networks**.

1. Under **Place singleton jobs in**, select the first AZ. Ops Manager runs any job with a
single instance in this AZ.

1. Under **Balance other jobs in**, select one or more other AZs. Ops Manager balances instances
of jobs with more than one instance across the AZs that you specify.

1. From the **Network** dropdown, select the runtime network that you created when configuring
the BOSH Director tile.

1. Click **Save**.

### <a id='exporter-config'></a> (Optional) Configure TKGI and Certificate Expiration Metric Exporter VMs

In the **TKGI Exporter Configuration** pane, you configure static IP addresses for the TKGI
metric exporter and certificate expiration metric exporter VMs. After processing these metrics,
the metric exporter VMs expose them in Prometheus exposition format on a secured endpoint.

To configure the **TKGI Exporter Configuration** pane:

<p class='note warning'><strong>Warning:</strong> The IP addresses you configure in the <strong>TKGI
  Exporter Configuration</strong> pane must not be within the reserved IP ranges you configured
  in the BOSH Director tile.</p>

1. Select **TKGI Exporter Configuration**.

1. (Optional) For **Static IP for TKGI Exporter VM**, enter a valid static IP address that
you want to reserve for the TKGI metric exporter VM. The TKGI metric exporter VM collects health
metrics from the BOSH Director. For more information, see [PKS Exporter (pks-exporter)](metrics.html#pks-exporter)
in _Healthwatch Metrics_.

1. (Optional) For **Static IP for Cert Expiration Exporter VM**, enter a valid static IP address
that you want to reserve for the certificate expiration metric exporter VM. The certificate
expiration metric exporter VM exposes metrics about when certificates in your Ops Manager deployment
are due to expire. For more information, see [Cert Expiration Exporter (cert-expiration-exporter)]
(metrics.html#cert-expiration-exporter) in _Healthwatch Metrics_ and [Certificate Monitoring]
(common-configurations/certificate-monitoring.html).

1. Click **Save**.

### <a id='sli-config'></a> (Optional) Configure the TKGI SLI Exporter VM

In the **TKGI SLI Exporter Configuration** pane, you configure the TKGI SLI exporter VM. The
TKGI SLI exporter VM processes SLIs that allow you to monitor whether the core functions of
the TKGI Command-Line Interface (TKGI CLI) are working as expected. The TKGI CLI enables developers
to create and manage Kubernetes clusters through TKGI. For more information, see [PKS SLI Exporter
(pks-sli-exporter)](metrics.html#pks-sli-exporter) in _Healthwatch
Metrics_.

To configure the **TKGI SLI Exporter Configuration** pane:

1. For **Static IP for TKGI SLI Exporter VM**, enter a valid static IP address that you want
to reserve for the TKGI SLI exporter VM. This IP address must not be within the reserved IP
ranges you configured in the BOSH Director tile.

1. For **Test Frequency in Seconds**, enter in seconds how frequently you want the TKGI SLI
exporter VM to run SLI tests.

1. (Optional) To configure TLS communication between the TKGI SLI exporter VM and the TKGI
API, choose one of the following options:
    * To configure the TKGI SLI exporter VM to use a self-signed certificate authority (CA)
    or a certificate that is signed by a self-signed CA when communicating with the TKGI API
    over TLS:
        1. For **TKGI API Certificate Authority**, provide the CA. If you provide a self-signed
        CA, it must be the same CA that signs the certificate in the TKGI API.
        1. When you provide a self-signed CA or certificate that is signed by a self-signed
        CA in this field, the **TKGI API Skip SSL Validation** checkbox becomes configurable.
        Disable the **TKGI API Skip SSL Validation** checkbox.
    * To configure the TKGI SLI exporter VM to skip SSL validation when communicating with
    the TKGI API over TLS, leave **TKGI API Certificate Authority** blank. The **TKGI API Skip
    SSL Validation** checkbox is enabled and not configurable by default. VMware does not recommend
    skipping SSL validation in a production environment.

1. Click **Save**.

### <a id='bosh-exporter'></a> Configure the BOSH Health Metric Exporter VM

In the **BOSH Health Exporter Configuration** pane, you configure the AZ and VM type of the
BOSH health metric exporter VM. Healthwatch Exporter for TKGI periodically deploys the BOSH
health metric exporter VM. This VM creates a BOSH deployment, runs SLI tests on the BOSH deployment
to validate the health of the BOSH Director, and deletes the BOSH deployment once the SLI tests
are complete. Healthwatch Exporter for TKGI then deletes the BOSH health metric exporter VM.
For more information, see [Bosh Health Exporter (bosh-health-exporter)](metrics.html#bosh-health-exporter)
in _Healthwatch Metrics_.

To configure the **BOSH Health Exporter Configuration** pane:

1. Select **BOSH Health Exporter Configuration**.

1. Under **BOSH Health Check Availability Zone**, select the AZ on which you want Healthwatch
Exporter for TKGI to deploy the BOSH health metric exporter VM.

1. Under **BOSH Health Check VM Type**, select from the dropdown the type of VM you want Healthwatch
Exporter for TKGI to deploy.

1. Click **Save**.

### <a id='bosh-deployments'></a> (Optional) Configure the BOSH Deployment Metric Exporter VM

In the **Bosh Deployments Exporter Configuration** pane, you configure the authentication credentials
and a static IP address for the BOSH deployment metric exporter VM. This VM periodically checks
to see if any BOSH deployments other than the one created by the BOSH health metric exporter
VM are running. For more information, see [Bosh Deployments Exporter (bosh-deployments-exporter)]
(metrics.html#bosh-deployments-exporter) in _Healthwatch Metrics_.

To configure the **Bosh Deployments Exporter Configuration** pane:

1. Select **Bosh Deployments Exporter Configuration**.

1. For **Bosh Client Username and Secret**, you must create a new UAA client to enable the
BOSH deployment metric exporter VM to access the BOSH Director VM.
    1. Navigate to the Ops Manager Installation Dashboard.
    1. Click the **BOSH Director** tile.
    1. Select the **Status** tab.
    1. Record the **BOSH Director IP Address**, **Uaa Login Client Credentials**, and **Uaa
    Admin User Credentials**. For **Uaa Login Client Credentials** and **Uaa Admin User Credentials**,
    click **Link to Credential** to obtain the client secret.
    1. SSH into the Ops Manager VM by following the procedure in [Log In to the Ops Manager
    VM with SSH](https://docs.pivotal.io/ops-manager/install/trouble-advanced.html#ssh) in
    _Advanced Troubleshooting with the BOSH CLI_ in the Ops Manager documentation.
    1. Target the UAA instance for the BOSH Director by running:

        ```
        uaac target https://BOSH-DIRECTOR-IP:8443 --skip-ssl-validation
        ```
        Where `BOSH-DIRECTOR-IP` is the IP address of your BOSH Director instance that you
        recorded from the **Status** tab in the BOSH Director tile in a previous step.
    1. Log in to the UAA instance by running:

        ```
        uaac token owner get login -s UAA-LOGIN-CLIENT-SECRET
        ```
        Where `UAA-LOGIN-CLIENT-SECRET` is the UAA login client secret you recorded from the
        **Status** tab in the BOSH Director tile in a previous step.
    1. When prompted, enter the UAA admin client username and secret you recorded in a previous
    step.
    1. Create a UAA client for the BOSH deployment metric exporter VM by running:

        ```
        uaac client add CLIENT-USERNAME \
          --secret CLIENT-SECRET \
          --authorized_grant_types client_credentials,refresh_token \
          --authorities bosh.read \
          --scope bosh.read
        ```
        Where:
        * `CLIENT-USERNAME` is the client username you want to set for the UAA client.
        * `CLIENT-SECRET` is the client secret you want to set for the UAA client.
    1. Return to the **Bosh Deployments Exporter Configuration** pane in the **Healthwatch
    Exporter for TKGI** tile.
    1. Enter the username and secret for the UAA client you just created in **Bosh Client Username
    and Secret**.

1. For **Static IP for Bosh Deployments Exporter VM**, enter a valid static IP address that
you want to reserve for the BOSH deployment metric exporter VM. This IP address must not be
within the reserved IP ranges you configured in the BOSH Director tile.

1. Click **Save**.

### <a id='errands'></a> (Optional) Configure Errands

Errands are scripts that Ops Manager runs automatically when it installs or uninstalls a product,
such as a new version of Healthwatch Exporter for TKGI. There are two types of errands: _post-deploy
errands_ run after the product is installed, and _pre-delete errands_ run before the product
is uninstalled. However, there are no pre-delete errands for Healthwatch Exporter for TKGI.

By default, Ops Manager always runs all errands.

In the **Errands** pane, you can select **On** to always run an errand or **Off** to never
run it.

For more information about how Ops Manager manages errands, see [Managing Errands in Ops Manager]
(https://docs.pivotal.io/ops-manager/install/managing_errands.html) in the Ops Manager documentation.

To configure the **Errands** pane:

1. Select **Errands**.

1. Choose whether to always run or never run the **Smoke Tests** errand. This errand verifies
that the metric exporter VMs are running.

1. Click **Save**.

### <a id='syslog'></a> (Optional) Configure Syslog

In the **Syslog** pane, you can configure system logging in Healthwatch Exporter for TKGI to
forward log messages from tile component VMs to an external destination for troubleshooting,
such as a remote server or external syslog aggregation service.

To configure the **Syslog** pane:

1. Select **Syslog**.

1. Under **Do you want to configure Syslog forwarding?**, select one of the following options:
    * **No, do not forward Syslog:** Disables syslog forwarding.
    * **Yes:** Enables syslog forwarding and allows you to edit the configuration fields described
    below.

1. For **Address**, enter the IP address or DNS domain name of your external destination.

1. For **Port**, enter a port on which your external destination listens.

1. For **Transport Protocol**, select **TCP** or **UDP** from the dropdown. This determines
which transport protocol Healthwatch Exporter for TKGI uses to forward system logs to
your external destination.

1. (Optional) To transmit logs over TLS:
  1. Select the **Enable TLS** checkbox. This checkbox is disabled by default.
  1. For **Permitted Peer**, enter either the name or SHA1 fingerprint of the remote peer.
  1. For **SSL Certificate**, enter the SSL certificate for your external destination.

1. (Optional) For **Queue Size**, specify the number of log messages Healthwatch Exporter for
TKGI can hold in a buffer at a time before sending them to your external destination.
The default value is `100000`.

1. (Optional) To forward debug logs to your external destination, enable the **Forward Debug
Logs** checkbox. This checkbox is disabled by default.

1. (Optional) To specify a custom syslog rule, enter it in **Custom rsyslog configuration**
in RainerScript syntax. For more information about custom syslog rules, see [Customizing Platform
Log Forwarding](https://docs.pivotal.io/application-service/operating/custom-syslog-rules.html)
in the TAS for VMs documentation. For more information about RainerScript syntax, see the [rsyslog]
(https://www.rsyslog.com/doc/v8-stable/rainerscript/index.html) documentation.

1. Click **Save Syslog Settings**.

### <a id='resource-config'></a> (Optional) Configure Resources

In the **Resource Config** pane, you can scale Healthwatch Exporter for TKGI VMs up or down
according to the needs of your deployment, as well as associate load balancers with a group
of VMs. For example, you can scale the persistent disk size of a metric exporter VM to enable
longer data retention.

To configure the **Resource Config** pane:

1. Select **Resource Config**.

1. (Optional) To scale a job, select an option from the dropdown for the resource you want
to modify:
    * **Instances:** Configures the number of instances each job has.
    * **VM Type:** Configures the type of VM used in each instance.
    * **Persistent Disk Type:** Configures the amount of persistent disk space to allocate
    to the job.

1. (Optional) To add a load balancer to a job:
  1. Click the icon next to the job name.
  1. For **Load Balancers**, enter the name of your load balancer.
  1. Ensure that the **Internet Connected** checkbox is disabled. Enabling this checkbox gives
  VMs a public IP address that enables outbound Internet access.

1. Click **Save**.


## <a id='apply-changes'></a> Deploy Healthwatch Exporter for TKGI

To complete your installation of the Healthwatch Exporter for TKGI tile:

1. Return to the Ops Manager Installation Dashboard.

1. Click **Review Pending Changes**.

1. Click **Apply Changes**.

For more information, see [Reviewing Pending Product Changes](https://docs.pivotal.io/ops-manager/install/review-pending-changes.html)
in the Ops Manager documentation.


## <a id='scrape-job-config'></a> Configure a Scrape Job for Healthwatch Exporter for TKGI

After you have successfully deployed Healthwatch Exporter for TKGI, you must configure a scrape
job in the Prometheus VM that exists within your metrics monitoring system, unless you installed
Healthwatch Exporter for TKGI on the same Ops Manager foundation as the Healthwatch tile. Follow
the procedure in one of the following sections, depending on which monitoring system you use:

* If you monitor metrics using the Healthwatch tile on your Ops Manager foundation, see [Configure
a Scrape Job for Healthwatch Exporter for TKGI in Healthwatch](#scraping-healthwatch) below.
  <p class='note'><strong>Note:</strong> You only need to configure a scrape job for installations
  of Healthwatch Exporter for TKGI that are not on the same foundation as your Healthwatch
  installation. The Prometheus VM in the Healthwatch tile automatically discovers and scrapes
  exporter tiles that are installed on the same foundation as Healthwatch.</p>

* If you monitor metrics using a service or database located outside your Ops Manager foundation,
such as an external time series database (TSDB) or an installation of Healthwatch on the TKGI
Control Plane, see [Configure a Scrape Job for Healthwatch Exporter for TKGI in an External
Monitoring System](#scraping-external) below.

### <a id='scraping-healthwatch'></a> Configure a Scrape Job for Healthwatch Exporter for TKGI in Healthwatch

To configure a scrape job for Healthwatch Exporter for TKGI in the Healthwatch tile on your
Ops Manager foundation, see [(Optional) Configure Prometheus](installing.html#prometheus) in
_Installing Healthwatch_.

### <a id='scraping-external'></a> Configure a Scrape Job for Healthwatch Exporter for TKGI in an External Monitoring System

To configure a scrape job for Healthwatch Exporter for TKGI in a service or database that is
located outside your Ops Manager foundation:

1. Open network communication paths from your external service or database to the metric exporter
VMs in Healthwatch Exporter for TKGI. The procedure to open these network paths differs depending
on your Ops Manager foundation's IaaS. For a list of TCP ports used by each metric exporter
VM, see [Required Networking Rules for Healthwatch Exporter for TKGI](architecture.html#network-rules-pks)
in _Healthwatch Architecture_.

1. In the `scrape_config` section of the Prometheus configuration file, create a scrape job
for your Ops Manager foundation. Under `static_config`, specify the TCP ports of each metric
exporter VM as static targets for the IP address of your external service or database. For
example:

    ```
    job_name: foundation-1
    metrics_path: /metrics
    scheme: https
    static_configs:
    - targets:
      - "1.2.3.4:8443"
      - "1.2.3.4:25555"
      - "1.2.3.4:443"
      - "1.2.3.4:25595"
      - "1.2.3.4:9021"
    ```
    For more information, see [&#60;scrape_config>](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config)
    and [&#60;static_config>](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#static_config)
    in _Configuration_ in the Prometheus documentation.
